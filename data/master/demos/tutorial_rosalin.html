
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><meta content="The Rosalin optimizer uses a measurement-frugal optimization strategy to minimize the number of times a quantum computer is accessed." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/sphx_glr_tutorial_rosalin_002.png" property="og:image" />

  

  <meta property="og:title" content="Frugal shot optimization with Rosalin &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_rosalin.html">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="The Rosalin optimizer uses a measurement-frugal optimization strategy to minimize the number of times a quantum computer is accessed." name="description" />
  

  <link href="https://fonts.googleapis.com/css?family=Noto+Serif" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Noto+Sans" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

  <!-- Material Design Bootstrap -->
  <!-- <link href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/css/mdb.min.css" rel="stylesheet"> -->

  <!-- nanoscroller -->
  <link rel="stylesheet" type="text/css" href="../_static/css/nanoscroller.css" />

  <!-- lightslider -->
  <link type="text/css" rel="stylesheet" href="../_static/css/lightslider.min.css" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       SVG: { linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           bm: ['\\mathbf{\#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['I',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           diag: ['\\mathrm{diag} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0]
         }
       }
     });
     </script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-130507810-1');
      </script>

  <title>Frugal shot optimization with Rosalin &#8212; PennyLane</title>
  
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/xanadu_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_rosalin.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Feedback-Based Quantum Optimization (FALQON)" href="tutorial_falqon.html" />
    <link rel="prev" title="Quantum circuit structure learning" href="tutorial_rotoselect.html" /> 
  </head><body><link rel="stylesheet" type="text/css" href="../_static/xanadu_gallery.css" />
  <!--Navbar-->
<nav class="navbar navbar-expand-lg navbar-light white sticky-top">

  <!-- Navbar brand -->
  <a class="navbar-brand" href="https://pennylane.ai">
    <img class="pr-1" src="../_static/xanadu_x.png" width="28px"></img>
    <img src="../_static/pennylane.png" width="180px"></img>
  </a>

  <!-- Collapse button -->
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
    aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <!-- Collapsible content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links -->
    <ul class="navbar-nav mr-auto">
      <li class="nav-item active">
        <a class="nav-link" href="https://pennylane.ai/qml">Quantum machine learning
          <span class="sr-only">(current)</span>
        </a>
      </li>
      <li class="nav-item">
        <a href="https://pennylane.ai/qml/demonstrations.html" class="nav-link">Demos</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/install.html">Install</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/plugins.html">Plugins</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.readthedocs.io">Documentation</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/blog">Blog</a>
      </li>
      <li class="nav-item">
        <a class="nav-link q-hack-link" href="https://qhack.ai">
          <img src="https://pennylane.ai/img/qhack_plain_black.png">
        </a>
      </li>
    </ul>
    <!-- Links -->

    <ul class="navbar-nav ml-auto nav-flex-icons">
      <li class="nav-item">
        <a class="nav-link" href="http://pennylane.ai/faq.html">
          <i class="fab fas fa-question"></i> FAQ
        </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://discuss.pennylane.ai">
          <i class="fab fab fa-discourse"></i> Support
        </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://github.com/XanaduAI/PennyLane">
          <i class="fab fa-github"></i> GitHub
        </a>
      </li>
    </ul>
  </div>
  <!-- Collapsible content -->
</nav>
<!--/.Navbar-->

<script type="text/javascript">
var isDemoPages = window.location.pathname.includes('/demos_') || window.location.pathname.includes('/demonstrations') || window.location.pathname.includes('/demos/');

if (isDemoPages) {
  var $navItems = $('.nav-item');

  var previousActiveLink = $navItems.filter(function(index, item) {
    var $item = $(item);
    return $item.hasClass('active') && $item.innerText !== 'Demos';
  });

  if (previousActiveLink.length) $(previousActiveLink[0]).removeClass('active');

  var demoLink = $navItems.filter(function(index, item) {
    return item.innerText === 'Demos';
  });

  if (demoLink.length) $(demoLink[0]).addClass('active');
}
</script>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial_falqon.html" title="Feedback-Based Quantum Optimization (FALQON)"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial_rotoselect.html" title="Quantum circuit structure learning"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_optimization.html" accesskey="U">Optimization</a> &#187;</li> 
      </ul>
    </div>
        <div id="content">


          <div id="right-column">
            <div class="document clearer body">

              <div class="container-wrapper">

                <div role="navigation" aria-label="breadcrumbs navigation">
                  <ol class="breadcrumb">
                  </ol>
                </div>

              
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-demos-tutorial-rosalin-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="frugal-shot-optimization-with-rosalin">
<span id="sphx-glr-demos-tutorial-rosalin-py"></span><h1>Frugal shot optimization with Rosalin<a class="headerlink" href="#frugal-shot-optimization-with-rosalin" title="Permalink to this headline">¶</a></h1>
<p><script type="text/javascript">
    var related_tutorials = ["tutorial_vqe.html", "tutorial_quantum_natural_gradient.html", "tutorial_doubly_stochastic.html", "tutorial_rotoselect.html"];
    var related_tutorials_titles = ['Variational quantum eigensolver', 'Quantum natural gradient', 'Doubly stochastic gradient descent', 'Quantum circuit structure learning'];
</script></p>
<p><em>Author: PennyLane dev team. Posted: 19 May 2020. Last updated: 13 April 2021.</em></p>
<p>In this tutorial we investigate and implement the Rosalin (Random Operator Sampling for
Adaptive Learning with Individual Number of shots) from
Arrasmith et al. <a class="footnote-reference" href="#arrasmith2020" id="id1">[1]</a>. In this paper, a strategy
is introduced for reducing the number of shots required when optimizing variational quantum
algorithms, by both:</p>
<ul class="simple">
<li>Frugally adapting the number of shots used per parameter update, and</li>
<li>Performing a weighted sampling of operators from the cost Hamiltonian.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The Rosalin optimizer is available in PennyLane via the
<a class="reference external" href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.ShotAdaptiveOptimizer.html#pennylane.ShotAdaptiveOptimizer" title="(in PennyLane v0.18)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShotAdaptiveOptimizer</span></code></a>.</p>
</div>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>While a large number of papers in variational quantum algorithms focus on the
choice of circuit ansatz, cost function, gradient computation, or initialization method,
the optimization strategy—an important component affecting both convergence time and
quantum resource dependence—is not as frequently considered. Instead, common
‘out-of-the-box’ classical optimization techniques, such as gradient-free
methods (COBLYA, Nelder-Mead), gradient-descent, and Hessian-free methods (L-BFGS) tend to be used.</p>
<p>However, for variational algorithms such as <a class="reference internal" href="tutorial_vqe.html"><span class="doc">VQE</span></a>, which involve evaluating
a large number of non-commuting operators in the cost function, decreasing the number of
quantum evaluations required for convergence, while still minimizing statistical noise, can
be a delicate balance.</p>
<p>Recent work has highlighted that ‘quantum-aware’ optimization techniques
can lead to marked improvements when training variational quantum algorithms:</p>
<ul class="simple">
<li><a class="reference internal" href="tutorial_quantum_natural_gradient.html"><span class="doc">Quantum natural gradient</span></a> descent by Stokes et al. <a class="footnote-reference" href="#stokes2019" id="id2">[2]</a>, which
takes into account the quantum geometry during the gradient-descent update step.</li>
<li>The work of Sweke et al. <a class="footnote-reference" href="#sweke2019" id="id3">[3]</a>, which shows
that quantum gradient descent with a finite number of shots is equivalent to
<a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a>,
and has guaranteed convergence. Furthermore, combining a finite number of shots with
weighted sampling of the cost function terms leads to <a class="reference internal" href="tutorial_doubly_stochastic.html"><span class="doc">Doubly stochastic gradient descent</span></a>.</li>
<li>The iCANS (individual Coupled Adaptive Number of Shots) optimization technique by
Jonas Kuebler et al. <a class="footnote-reference" href="#kubler2020" id="id4">[4]</a> adapts the number
of shots measurements during training, by maximizing the expected gain per shot.</li>
</ul>
<p>In this latest result by Arrasmith et al. <a class="footnote-reference" href="#arrasmith2020" id="id5">[1]</a>, the
idea of doubly stochastic gradient descent has been used to extend the iCANS optimizer,
resulting in faster convergence.</p>
<p>Over the course of this tutorial, we will explore their results; beginning first with a
demonstration of <em>weighted random sampling</em> of the cost Hamiltonian operators, before
combining this with the shot-frugal iCANS optimizer to perform doubly stochastic
Rosalin optimization.</p>
</div>
<div class="section" id="weighted-random-sampling">
<h2>Weighted random sampling<a class="headerlink" href="#weighted-random-sampling" title="Permalink to this headline">¶</a></h2>
<p>Consider a Hamiltonian <span class="math notranslate nohighlight">\(H\)</span> expanded as a weighted sum of operators <span class="math notranslate nohighlight">\(h_i\)</span> that can
be directly measured:</p>
<div class="math notranslate nohighlight">
\[H = \sum_{i=1}^N c_i h_i.\]</div>
<p>Due to the linearity of expectation values, the expectation value of this Hamiltonian
can be expressed as the weighted sum of each individual term:</p>
<div class="math notranslate nohighlight">
\[\langle H\rangle = \sum_{i=1}^N c_i \langle h_i\rangle.\]</div>
<p>In the <a class="reference internal" href="tutorial_doubly_stochastic.html"><span class="doc">doubly stochastic gradient descent demonstration</span></a>,
we estimated this expectation value by <strong>uniformly sampling</strong> a subset of the terms
at each optimization step, and evaluating each term by using the same finite number of shots
<span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>However, what happens if we use a weighted approach to determine how to distribute
our samples across the terms of the Hamiltonian? In <strong>weighted random sampling</strong> (WRS),
the number of shots used to determine the expectation value <span class="math notranslate nohighlight">\(\langle h_i\rangle\)</span>
is a discrete random variable distributed according to a
<a class="reference external" href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial distribution</a>,</p>
<div class="math notranslate nohighlight">
\[S \sim \text{Multinomial}(p_i),\]</div>
<p>with event probabilities</p>
<div class="math notranslate nohighlight">
\[p_i = \frac{|c_i|}{\sum_i |c_i|}.\]</div>
<p>That is, the number of shots assigned to the measurement of the expectation value of the
<span class="math notranslate nohighlight">\(i\text{th}\)</span> term of the Hamiltonian is drawn from a probability distribution
<em>proportional to the magnitude of its coefficient</em> <span class="math notranslate nohighlight">\(c_i\)</span>.</p>
<p>To see this strategy in action, consider the Hamiltonian</p>
<div class="math notranslate nohighlight">
\[H = 2I\otimes X + 4 I\otimes Z  - X\otimes X + 5Y\otimes Y + 2 Z\otimes X.\]</div>
<p>We can solve for the ground state energy using the variational quantum eigensolver (VQE) algorithm.</p>
<p>First, let’s import NumPy and PennyLane, and define our Hamiltonian.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>

<span class="c1"># set the random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">coeffs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">obs</span> <span class="o">=</span> <span class="p">[</span>
  <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">@</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliY.html#pennylane.PauliY" title="pennylane.PauliY" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliY</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">@</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliY.html#pennylane.PauliY" title="pennylane.PauliY" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliY</span></a><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">@</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">]</span>
</pre></div>
</div>
<p>We can now create our quantum device (let’s use the <code class="docutils literal notranslate"><span class="pre">default.qubit</span></code> simulator),
and begin constructing some QNodes to evaluate each observable. For our ansatz, we’ll use the
<a class="reference external" href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.templates.layers.StronglyEntanglingLayers.html#pennylane.templates.layers.StronglyEntanglingLayers" title="(in PennyLane v0.18)"><code class="xref py py-class docutils literal notranslate"><span class="pre">StronglyEntanglingLayers</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">expval</span>
<span class="kn">from</span> <span class="nn">pennylane.init</span> <span class="kn">import</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.init.strong_ent_layers_uniform.html#pennylane.init.strong_ent_layers_uniform" title="pennylane.init.strong_ent_layers_uniform" class="sphx-glr-backref-module-pennylane-init sphx-glr-backref-type-py-function"><span class="n">strong_ent_layers_uniform</span></a>
<span class="kn">from</span> <span class="nn">pennylane.templates.layers</span> <span class="kn">import</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.operation.Operation.html#pennylane.operation.Operation" title="pennylane.operation.Operation" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class"><span class="n">StronglyEntanglingLayers</span></a>

<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_wires</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># create a device that estimates expectation values using a finite number of shots</span>
<span class="n">non_analytic_dev</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">num_wires</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># create a device that calculates exact expectation values</span>
<span class="n">analytic_dev</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">num_wires</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>We use <a class="reference external" href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.map.html#pennylane.map" title="(in PennyLane v0.18)"><code class="xref py py-func docutils literal notranslate"><span class="pre">map()</span></code></a> to map our ansatz over our list of observables,
returning a collection of QNodes, each one evaluating the expectation value
of each Hamiltonian.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.map.html#pennylane.map" title="pennylane.map" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">map</span></a><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.operation.Operation.html#pennylane.operation.Operation" title="pennylane.operation.Operation" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class"><span class="n">StronglyEntanglingLayers</span></a><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">non_analytic_dev</span><span class="p">,</span> <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;parameter-shift&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, let’s set the total number of shots, and determine the probability
for sampling each Hamiltonian term.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">total_shots</span> <span class="o">=</span> <span class="mi">8000</span>
<span class="n">prob_shots</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prob_shots</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0.14285714 0.28571429 0.07142857 0.35714286 0.14285714]
</pre></div>
</div>
<p>We can now use SciPy to create our multinomial distributed random variable
<span class="math notranslate nohighlight">\(S\)</span>, using the number of trials (total shot number) and probability values:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multinomial</span>
<span class="n">si</span> <span class="o">=</span> <span class="n">multinomial</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">total_shots</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">prob_shots</span><span class="p">)</span>
</pre></div>
</div>
<p>Sampling from this distribution will provide the number of shots used to
sample each term in the Hamiltonian:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">si</span><span class="o">.</span><span class="n">rvs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">samples</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[1191 2262  552 2876 1119]
8000
</pre></div>
</div>
<p>As expected, if we sum the sampled shots per term, we recover the total number of shots.</p>
<p>Let’s now create our cost function. Recall that the cost function must do the
following:</p>
<ol class="arabic simple">
<li>It must sample from the multinomial distribution we created above,
to determine the number of shots <span class="math notranslate nohighlight">\(s_i\)</span> to use to estimate the expectation
value of the ith Hamiltonian term.</li>
<li>It then must estimate the expectation value <span class="math notranslate nohighlight">\(\langle h_i\rangle\)</span>
by querying the required QNode.</li>
<li>And, last but not least, estimate the expectation value
<span class="math notranslate nohighlight">\(\langle H\rangle = \sum_i c_i\langle h_i\rangle\)</span>.</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="c1"># sample from the multinomial distribution</span>
    <span class="n">shots_per_term</span> <span class="o">=</span> <span class="n">si</span><span class="o">.</span><span class="n">rvs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a><span class="p">,</span> <span class="n">coeffs</span><span class="p">,</span> <span class="n">prob_shots</span><span class="p">,</span> <span class="n">shots_per_term</span><span class="p">):</span>

        <span class="c1"># evaluate the QNode corresponding to</span>
        <span class="c1"># the Hamiltonian term, and add it on to our running sum</span>
        <span class="n">result</span> <span class="o">+=</span> <span class="n">c</span> <span class="o">*</span> <span class="n">h</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
<p>Evaluating our cost function with some initial parameters, we can test out
that our cost function evaluates correctly.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">init_params</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.init.strong_ent_layers_uniform.html#pennylane.init.strong_ent_layers_uniform" title="pennylane.init.strong_ent_layers_uniform" class="sphx-glr-backref-module-pennylane-init sphx-glr-backref-type-py-function"><span class="n">strong_ent_layers_uniform</span></a><span class="p">(</span><span class="n">n_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">n_wires</span><span class="o">=</span><span class="n">num_wires</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cost</span><span class="p">(</span><span class="n">init_params</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/runner/work/qml/qml/demonstrations/tutorial_rosalin.py:217: UserWarning: The init module will be deprecated soon, since templates can now provide a method that returns the shape of parameter tensors.
-0.8395887630997874
</pre></div>
</div>
<p>Performing the optimization, with the number of shots randomly
determined at each optimization step:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">AdamOptimizer</span></a><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">init_params</span>

<span class="n">cost_wrs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shots_wrs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">params</span><span class="p">,</span> <span class="n">_cost</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer.step_and_cost" title="pennylane.AdamOptimizer.step_and_cost" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-method"><span class="n">opt</span><span class="o">.</span><span class="n">step_and_cost</span></a><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">cost_wrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_cost</span><span class="p">)</span>
    <span class="n">shots_wrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_shots</span><span class="o">*</span><span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Step </span><span class="si">{}</span><span class="s2">: cost = </span><span class="si">{}</span><span class="s2"> shots used = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost_wrs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">shots_wrs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Step 0: cost = -0.47971271815214855 shots used = 0
Step 1: cost = -1.6879973520840041 shots used = 8000
Step 2: cost = -2.437928256197112 shots used = 16000
Step 3: cost = -2.9300968884147647 shots used = 24000
Step 4: cost = -3.7779069617997116 shots used = 32000
Step 5: cost = -3.8889841568955115 shots used = 40000
Step 6: cost = -4.508059711766957 shots used = 48000
Step 7: cost = -4.71114219758592 shots used = 56000
Step 8: cost = -4.984457128293103 shots used = 64000
Step 9: cost = -5.597084424095087 shots used = 72000
Step 10: cost = -5.456976403687039 shots used = 80000
Step 11: cost = -5.736752824027413 shots used = 88000
Step 12: cost = -6.220317925041974 shots used = 96000
Step 13: cost = -6.45162161927903 shots used = 104000
Step 14: cost = -6.563539211112225 shots used = 112000
Step 15: cost = -6.487339064303318 shots used = 120000
Step 16: cost = -6.69261841162329 shots used = 128000
Step 17: cost = -6.909230576241427 shots used = 136000
Step 18: cost = -7.05156660241221 shots used = 144000
Step 19: cost = -7.163688069859358 shots used = 152000
Step 20: cost = -7.191791478058647 shots used = 160000
Step 21: cost = -7.191694602776715 shots used = 168000
Step 22: cost = -7.430122007574104 shots used = 176000
Step 23: cost = -7.245621601209081 shots used = 184000
Step 24: cost = -7.539044265851978 shots used = 192000
Step 25: cost = -7.532847998808006 shots used = 200000
Step 26: cost = -7.44257222073886 shots used = 208000
Step 27: cost = -7.439951968648378 shots used = 216000
Step 28: cost = -7.734568855081575 shots used = 224000
Step 29: cost = -7.618221322585628 shots used = 232000
Step 30: cost = -7.651544920606065 shots used = 240000
Step 31: cost = -7.5069088885777155 shots used = 248000
Step 32: cost = -7.780301321189146 shots used = 256000
Step 33: cost = -7.4456447455856445 shots used = 264000
Step 34: cost = -7.403560444278863 shots used = 272000
Step 35: cost = -7.666718876831026 shots used = 280000
Step 36: cost = -7.7178910518866415 shots used = 288000
Step 37: cost = -7.375680885292107 shots used = 296000
Step 38: cost = -7.665568049279896 shots used = 304000
Step 39: cost = -7.568101693343673 shots used = 312000
Step 40: cost = -7.524188200359864 shots used = 320000
Step 41: cost = -7.525528734255245 shots used = 328000
Step 42: cost = -7.57734861403185 shots used = 336000
Step 43: cost = -7.76844833198197 shots used = 344000
Step 44: cost = -7.797619087079373 shots used = 352000
Step 45: cost = -7.879148884805528 shots used = 360000
Step 46: cost = -7.744030492750696 shots used = 368000
Step 47: cost = -7.6484739221198765 shots used = 376000
Step 48: cost = -7.679623095926702 shots used = 384000
Step 49: cost = -7.607476988501242 shots used = 392000
Step 50: cost = -7.856041856821188 shots used = 400000
Step 51: cost = -7.644473030321983 shots used = 408000
Step 52: cost = -7.593159311741706 shots used = 416000
Step 53: cost = -7.606939212888227 shots used = 424000
Step 54: cost = -7.621128949485829 shots used = 432000
Step 55: cost = -7.743568287057952 shots used = 440000
Step 56: cost = -7.6325929460598525 shots used = 448000
Step 57: cost = -7.718256562367575 shots used = 456000
Step 58: cost = -7.861601938446393 shots used = 464000
Step 59: cost = -7.666115854972354 shots used = 472000
Step 60: cost = -7.644148944168839 shots used = 480000
Step 61: cost = -7.771569192260795 shots used = 488000
Step 62: cost = -7.776898446282362 shots used = 496000
Step 63: cost = -7.711006891533269 shots used = 504000
Step 64: cost = -7.748650044666392 shots used = 512000
Step 65: cost = -7.690723991927554 shots used = 520000
Step 66: cost = -7.694117031088106 shots used = 528000
Step 67: cost = -7.793250125674997 shots used = 536000
Step 68: cost = -7.926049735334674 shots used = 544000
Step 69: cost = -7.686292326080605 shots used = 552000
Step 70: cost = -7.745774212716911 shots used = 560000
Step 71: cost = -7.625346751584894 shots used = 568000
Step 72: cost = -7.846664469958039 shots used = 576000
Step 73: cost = -7.860275655123486 shots used = 584000
Step 74: cost = -7.593043619614097 shots used = 592000
Step 75: cost = -7.7969799318129045 shots used = 600000
Step 76: cost = -7.837545360539077 shots used = 608000
Step 77: cost = -7.845253964960701 shots used = 616000
Step 78: cost = -7.941652692590529 shots used = 624000
Step 79: cost = -7.967099906804574 shots used = 632000
Step 80: cost = -7.803163356121793 shots used = 640000
Step 81: cost = -7.665600401510319 shots used = 648000
Step 82: cost = -8.09158124610039 shots used = 656000
Step 83: cost = -7.774883584668083 shots used = 664000
Step 84: cost = -7.758175214036924 shots used = 672000
Step 85: cost = -7.9169924228411865 shots used = 680000
Step 86: cost = -7.670199051467696 shots used = 688000
Step 87: cost = -8.085682024006845 shots used = 696000
Step 88: cost = -7.8433919424579095 shots used = 704000
Step 89: cost = -7.755236580472145 shots used = 712000
Step 90: cost = -7.847624689390126 shots used = 720000
Step 91: cost = -8.122239105086607 shots used = 728000
Step 92: cost = -7.922374192271718 shots used = 736000
Step 93: cost = -7.904676929818973 shots used = 744000
Step 94: cost = -7.909417248833883 shots used = 752000
Step 95: cost = -8.06033491620787 shots used = 760000
Step 96: cost = -7.765636196903123 shots used = 768000
Step 97: cost = -7.801666008865329 shots used = 776000
Step 98: cost = -8.066513329432457 shots used = 784000
Step 99: cost = -7.8942080196569675 shots used = 792000
</pre></div>
</div>
<p>Let’s compare this against an optimization not using weighted random sampling.
Here, we will split the 8000 total shots evenly across all Hamiltonian terms,
also known as <em>uniform deterministic sampling</em>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QubitDevice.html#pennylane.QubitDevice.shots" title="pennylane.QubitDevice.shots" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-attribute"><span class="n">non_analytic_dev</span><span class="o">.</span><span class="n">shots</span></a> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_shots</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">coeffs</span><span class="p">))</span>

<a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.map.html#pennylane.map" title="pennylane.map" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">map</span></a><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.operation.Operation.html#pennylane.operation.Operation" title="pennylane.operation.Operation" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class"><span class="n">StronglyEntanglingLayers</span></a><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">non_analytic_dev</span><span class="p">)</span>
<span class="n">cost</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.dot.html#pennylane.dot" title="pennylane.dot" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">dot</span></a><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a><span class="p">)</span>

<a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">AdamOptimizer</span></a><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">init_params</span>

<span class="n">cost_adam</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shots_adam</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">params</span><span class="p">,</span> <span class="n">_cost</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer.step_and_cost" title="pennylane.AdamOptimizer.step_and_cost" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-method"><span class="n">opt</span><span class="o">.</span><span class="n">step_and_cost</span></a><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">cost_adam</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_cost</span><span class="p">)</span>
    <span class="n">shots_adam</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_shots</span><span class="o">*</span><span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Step </span><span class="si">{}</span><span class="s2">: cost = </span><span class="si">{}</span><span class="s2"> shots used = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost_adam</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">shots_adam</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Step 0: cost = -0.38250000000000006 shots used = 0
Step 1: cost = -1.7450000000000006 shots used = 8000
Step 2: cost = -2.54875 shots used = 16000
Step 3: cost = -2.91 shots used = 24000
Step 4: cost = -3.4762500000000003 shots used = 32000
Step 5: cost = -4.08875 shots used = 40000
Step 6: cost = -4.586250000000001 shots used = 48000
Step 7: cost = -4.805 shots used = 56000
Step 8: cost = -4.925 shots used = 64000
Step 9: cost = -5.385000000000001 shots used = 72000
Step 10: cost = -5.4725 shots used = 80000
Step 11: cost = -5.63875 shots used = 88000
Step 12: cost = -5.796250000000001 shots used = 96000
Step 13: cost = -6.308750000000001 shots used = 104000
Step 14: cost = -6.2524999999999995 shots used = 112000
Step 15: cost = -6.706249999999999 shots used = 120000
Step 16: cost = -6.711250000000001 shots used = 128000
Step 17: cost = -6.803749999999999 shots used = 136000
Step 18: cost = -6.94375 shots used = 144000
Step 19: cost = -7.2837499999999995 shots used = 152000
Step 20: cost = -7.4 shots used = 160000
Step 21: cost = -7.38375 shots used = 168000
Step 22: cost = -7.40125 shots used = 176000
Step 23: cost = -7.4775 shots used = 184000
Step 24: cost = -7.58 shots used = 192000
Step 25: cost = -7.623749999999999 shots used = 200000
Step 26: cost = -7.49625 shots used = 208000
Step 27: cost = -7.58375 shots used = 216000
Step 28: cost = -7.6312500000000005 shots used = 224000
Step 29: cost = -7.13375 shots used = 232000
Step 30: cost = -7.47 shots used = 240000
Step 31: cost = -7.6075 shots used = 248000
Step 32: cost = -7.34875 shots used = 256000
Step 33: cost = -7.6525 shots used = 264000
Step 34: cost = -7.572500000000001 shots used = 272000
Step 35: cost = -7.390000000000001 shots used = 280000
Step 36: cost = -7.76375 shots used = 288000
Step 37: cost = -7.49 shots used = 296000
Step 38: cost = -7.61625 shots used = 304000
Step 39: cost = -7.695 shots used = 312000
Step 40: cost = -7.702499999999999 shots used = 320000
Step 41: cost = -7.59625 shots used = 328000
Step 42: cost = -7.733750000000001 shots used = 336000
Step 43: cost = -7.6875 shots used = 344000
Step 44: cost = -7.75875 shots used = 352000
Step 45: cost = -7.796250000000001 shots used = 360000
Step 46: cost = -7.7387500000000005 shots used = 368000
Step 47: cost = -7.92375 shots used = 376000
Step 48: cost = -7.6225 shots used = 384000
Step 49: cost = -7.8425 shots used = 392000
Step 50: cost = -7.74 shots used = 400000
Step 51: cost = -7.661250000000001 shots used = 408000
Step 52: cost = -7.786250000000001 shots used = 416000
Step 53: cost = -7.78875 shots used = 424000
Step 54: cost = -7.62375 shots used = 432000
Step 55: cost = -7.9375 shots used = 440000
Step 56: cost = -7.71625 shots used = 448000
Step 57: cost = -7.72375 shots used = 456000
Step 58: cost = -7.741250000000001 shots used = 464000
Step 59: cost = -7.811249999999999 shots used = 472000
Step 60: cost = -7.89 shots used = 480000
Step 61: cost = -7.74 shots used = 488000
Step 62: cost = -7.751250000000001 shots used = 496000
Step 63: cost = -7.71875 shots used = 504000
Step 64: cost = -7.695 shots used = 512000
Step 65: cost = -7.7325 shots used = 520000
Step 66: cost = -7.819999999999999 shots used = 528000
Step 67: cost = -7.981249999999999 shots used = 536000
Step 68: cost = -7.8 shots used = 544000
Step 69: cost = -7.89 shots used = 552000
Step 70: cost = -7.7125 shots used = 560000
Step 71: cost = -7.993750000000001 shots used = 568000
Step 72: cost = -7.772499999999999 shots used = 576000
Step 73: cost = -8.01125 shots used = 584000
Step 74: cost = -8.116249999999999 shots used = 592000
Step 75: cost = -7.9662500000000005 shots used = 600000
Step 76: cost = -7.7125 shots used = 608000
Step 77: cost = -7.8925 shots used = 616000
Step 78: cost = -7.967499999999999 shots used = 624000
Step 79: cost = -7.91375 shots used = 632000
Step 80: cost = -7.797499999999999 shots used = 640000
Step 81: cost = -7.9975000000000005 shots used = 648000
Step 82: cost = -7.99 shots used = 656000
Step 83: cost = -7.7124999999999995 shots used = 664000
Step 84: cost = -7.76875 shots used = 672000
Step 85: cost = -7.62 shots used = 680000
Step 86: cost = -7.822500000000001 shots used = 688000
Step 87: cost = -7.74625 shots used = 696000
Step 88: cost = -7.9137499999999985 shots used = 704000
Step 89: cost = -7.86125 shots used = 712000
Step 90: cost = -7.975 shots used = 720000
Step 91: cost = -7.89375 shots used = 728000
Step 92: cost = -8.1075 shots used = 736000
Step 93: cost = -7.775 shots used = 744000
Step 94: cost = -7.8999999999999995 shots used = 752000
Step 95: cost = -7.85625 shots used = 760000
Step 96: cost = -7.925000000000001 shots used = 768000
Step 97: cost = -8.0 shots used = 776000
Step 98: cost = -7.825000000000001 shots used = 784000
Step 99: cost = -7.999999999999999 shots used = 792000
</pre></div>
</div>
<p>Comparing these two techniques:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;seaborn&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">shots_wrs</span><span class="p">,</span> <span class="n">cost_wrs</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Adam WRS&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">shots_adam</span><span class="p">,</span> <span class="n">cost_adam</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost function value&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of shots&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="tutorial rosalin" class="sphx-glr-single-img" src="../_images/sphx_glr_tutorial_rosalin_001.png" />
<p>We can see that weighted random sampling performs just as well as the uniform
deterministic sampling. However, weighted random sampling begins to show a
non-negligible improvement over deterministic sampling for large Hamiltonians
with highly non-uniform coefficients. For example, see Fig (3) and (4) of
Arrasmith et al. <a class="footnote-reference" href="#arrasmith2020" id="id6">[1]</a>, comparing weighted random sampling VQE optimization
for both <span class="math notranslate nohighlight">\(\text{H}_2\)</span> and <span class="math notranslate nohighlight">\(\text{LiH}\)</span> molecules.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>While not covered here, another approach that could be taken is
<em>weighted deterministic sampling</em>. Here, the number of shots is distributed
across terms as per</p>
<div class="math notranslate nohighlight">
\[s_i = \left\lfloor N \frac{|c_i|}{\sum_i |c_i|}\right\rfloor,\]</div>
<p class="last">where <span class="math notranslate nohighlight">\(N\)</span> is the total number of shots.</p>
</div>
</div>
<div class="section" id="rosalin-frugal-shot-optimization">
<h2>Rosalin: Frugal shot optimization<a class="headerlink" href="#rosalin-frugal-shot-optimization" title="Permalink to this headline">¶</a></h2>
<p>We can see above that both methods optimize fairly well; weighted random
sampling converges just as well as evenly distributing the shots across
all Hamiltonian terms. However, deterministic shot distribution approaches
will always have a minimum shot value required per expectation value, as below
this threshold they become biased estimators. This is not the case with random
sampling; as we saw in the
<a class="reference internal" href="tutorial_doubly_stochastic.html"><span class="doc">doubly stochastic gradient descent demonstration</span></a>,
the introduction of randomness allows for as little
as a single shot per expectation term, while still remaining an unbiased estimator.</p>
<p>Using this insight, Arrasmith et al. <a class="footnote-reference" href="#arrasmith2020" id="id7">[1]</a> modified the iCANS frugal
shot-optimization technique <a class="footnote-reference" href="#kubler2020" id="id8">[4]</a> to include weighted random sampling, making it
‘doubly stochastic’.</p>
<div class="section" id="icans-optimizer">
<h3>iCANS optimizer<a class="headerlink" href="#icans-optimizer" title="Permalink to this headline">¶</a></h3>
<p>Two variants of the iCANS optimizer were introduced in Kübler et al., iCANS1 and iCANS2.
The iCANS1 optimizer, on which Rosalin is based, frugally distributes a shot budget
across the partial derivatives of each parameter, which are computed using the
<a class="reference internal" href="../glossary/quantum_gradient.html"><span class="doc">parameter-shift rule</span></a>. It works roughly as follows:</p>
<ol class="arabic">
<li><p class="first">The initial step of the optimizer is performed with some specified minimum
number of shots, <span class="math notranslate nohighlight">\(s_{min}\)</span>, for all partial derivatives.</p>
</li>
<li><p class="first">The parameter-shift rule is then used to estimate the gradient <span class="math notranslate nohighlight">\(g_i\)</span>
for each parameter <span class="math notranslate nohighlight">\(\theta_i\)</span>, parameters, as well as the <em>variances</em>
<span class="math notranslate nohighlight">\(v_i\)</span> of the estimated gradients.</p>
</li>
<li><p class="first">Gradient descent is performed for each parameter <span class="math notranslate nohighlight">\(\theta_i\)</span>, using
the pre-defined learning rate <span class="math notranslate nohighlight">\(\alpha\)</span> and the gradient information <span class="math notranslate nohighlight">\(g_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[\theta_i = \theta_i - \alpha g_i.\]</div>
</li>
<li><p class="first">The improvement in the cost function per shot, for a specific parameter value,
is then calculated via</p>
<div class="math notranslate nohighlight">
\[\gamma_i = \frac{1}{s_i} \left[ \left(\alpha - \frac{1}{2} L\alpha^2\right)
            g_i^2 - \frac{L\alpha^2}{2s_i}v_i \right],\]</div>
<p>where:</p>
<ul class="simple">
<li><span class="math notranslate nohighlight">\(L \leq \sum_i|c_i|\)</span> is the bound on the <a class="reference external" href="https://en.wikipedia.org/wiki/Lipschitz_continuity">Lipschitz constant</a> of the variational quantum algorithm objective function,</li>
<li><span class="math notranslate nohighlight">\(c_i\)</span> are the coefficients of the Hamiltonian, and</li>
<li><span class="math notranslate nohighlight">\(\alpha\)</span> is the learning rate, and <em>must</em> be bound such that <span class="math notranslate nohighlight">\(\alpha &lt; 2/L\)</span>
for the above expression to hold.</li>
</ul>
</li>
<li><p class="first">Finally, the new values of <span class="math notranslate nohighlight">\(s_i\)</span> (shots for partial derivative of parameter
<span class="math notranslate nohighlight">\(\theta_i\)</span>) is given by:</p>
<div class="math notranslate nohighlight">
\[s_i = \frac{2L\alpha}{2-L\alpha}\left(\frac{v_i}{g_i^2}\right)\propto
      \frac{v_i}{g_i^2}.\]</div>
</li>
</ol>
<p>In addition to the above, to counteract the presence of noise in the system, a
running average of <span class="math notranslate nohighlight">\(g_i\)</span> and <span class="math notranslate nohighlight">\(s_i\)</span> (<span class="math notranslate nohighlight">\(\chi_i\)</span> and <span class="math notranslate nohighlight">\(\xi_i\)</span> respectively)
are used when computing <span class="math notranslate nohighlight">\(\gamma_i\)</span> and <span class="math notranslate nohighlight">\(s_i\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In classical machine learning, the Lipschitz constant of the cost function is generally
unknown. However, for a variational quantum algorithm with cost of the form
<span class="math notranslate nohighlight">\(f(x) = \langle \psi(x) | \hat{H} |\psi(x)\rangle\)</span>,
an upper bound on the Lipschitz constant is given by <span class="math notranslate nohighlight">\(L &lt; \sum_i|c_i|\)</span>,
where <span class="math notranslate nohighlight">\(c_i\)</span> are the coefficients of <span class="math notranslate nohighlight">\(\hat{H}\)</span> when decomposed
into a linear combination of Pauli-operator tensor products.</p>
</div>
</div>
<div class="section" id="rosalin-implementation">
<h3>Rosalin implementation<a class="headerlink" href="#rosalin-implementation" title="Permalink to this headline">¶</a></h3>
<p>Let’s now modify iCANS above to incorporate weighted random sampling of Hamiltonian
terms — the Rosalin frugal shot optimizer.</p>
<p>Rosalin takes several hyper-parameters:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">min_shots</span></code>: the minimum number of shots used to estimate the expectations
of each term in the Hamiltonian. Note that this must be larger than 2 for the variance
of the gradients to be computed.</li>
<li><code class="docutils literal notranslate"><span class="pre">mu</span></code>: The running average constant <span class="math notranslate nohighlight">\(\mu\in[0, 1]\)</span>. Used to control how quickly the
number of shots recommended for each gradient component changes.</li>
<li><code class="docutils literal notranslate"><span class="pre">b</span></code>: Regularization bias. The bias should be kept small, but non-zero.</li>
<li><code class="docutils literal notranslate"><span class="pre">lr</span></code>: The learning rate. Recall from above that the learning rate <em>must</em> be such
that <span class="math notranslate nohighlight">\(\alpha &lt; 2/L = 2/\sum_i|c_i|\)</span>.</li>
</ul>
<p>Since the Rosalin optimizer has a state that must be preserved between optimization steps,
let’s use a class to create our optimizer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Rosalin</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a><span class="p">,</span> <span class="n">coeffs</span><span class="p">,</span> <span class="n">min_shots</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.07</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">coeffs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">lr</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The learning rate must be less than &quot;</span><span class="p">,</span> <span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz</span><span class="p">)</span>

        <span class="c1"># hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_shots</span> <span class="o">=</span> <span class="n">min_shots</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>  <span class="c1"># running average constant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>    <span class="c1"># regularization bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>  <span class="c1"># learning rate</span>

        <span class="c1"># keep track of the total number of shots used</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shots_used</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># total number of iterations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Number of shots per parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="o">+</span> <span class="n">min_shots</span>

        <span class="c1"># Running average of the parameter gradients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chi</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># Running average of the variance of the parameter gradients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">estimate_hamiltonian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">shots</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns an array containing length ``shots`` single-shot estimates</span>
<span class="sd">        of the Hamiltonian. The shots are distributed randomly over</span>
<span class="sd">        the terms in the Hamiltonian, as per a Multinomial distribution.</span>

<span class="sd">        Since we are performing single-shot estimates, the QNodes must be</span>
<span class="sd">        set to &#39;sample&#39; mode.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># determine the shot probability per term</span>
        <span class="n">prob_shots</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">))</span>

        <span class="c1"># construct the multinomial distribution, and sample</span>
        <span class="c1"># from it to determine how many shots to apply per term</span>
        <span class="n">si</span> <span class="o">=</span> <span class="n">multinomial</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">shots</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">prob_shots</span><span class="p">)</span>
        <span class="n">shots_per_term</span> <span class="o">=</span> <span class="n">si</span><span class="o">.</span><span class="n">rvs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">prob_shots</span><span class="p">,</span> <span class="n">shots_per_term</span><span class="p">):</span>

            <span class="c1"># if the number of shots is 0, do nothing</span>
            <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># evaluate the QNode corresponding to</span>
            <span class="c1"># the Hamiltonian term</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">h</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">res</span><span class="p">])</span>

            <span class="c1"># Note that, unlike above, we divide each term by the</span>
            <span class="c1"># probability per shot. This is because we are sampling one at a time.</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span> <span class="o">*</span> <span class="n">res</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate_grad_var</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">shots</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluate the gradient, as well as the variance in the gradient,</span>
<span class="sd">        for the ith parameter in params, using the parameter-shift rule.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">shift</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="n">shift_forward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_hamiltonian</span><span class="p">(</span><span class="n">params</span> <span class="o">+</span> <span class="n">shift</span><span class="p">,</span> <span class="n">shots</span><span class="p">)</span>
        <span class="n">shift_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_hamiltonian</span><span class="p">(</span><span class="n">params</span> <span class="o">-</span> <span class="n">shift</span><span class="p">,</span> <span class="n">shots</span><span class="p">)</span>

        <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">shift_forward</span> <span class="o">-</span> <span class="n">shift_backward</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">((</span><span class="n">shift_forward</span> <span class="o">-</span> <span class="n">shift_backward</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">g</span><span class="p">,</span> <span class="n">s</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform a single step of the Rosalin optimizer.&quot;&quot;&quot;</span>
        <span class="c1"># keep track of the number of shots run</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shots_used</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">))</span>

        <span class="c1"># compute the gradient, as well as the variance in the gradient,</span>
        <span class="c1"># using the number of shots determined by the array s.</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">S</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">p_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndindex</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">p_ind</span><span class="p">:</span>
            <span class="c1"># loop through each parameter, performing</span>
            <span class="c1"># the parameter-shift rule</span>
            <span class="n">g_</span><span class="p">,</span> <span class="n">s_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_grad_var</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
            <span class="n">grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g_</span><span class="p">)</span>
            <span class="n">S</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s_</span><span class="p">)</span>

        <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">grad</span><span class="p">),</span> <span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># gradient descent update</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">params</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">chi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c1"># running average of the gradient variance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">*</span> <span class="n">S</span>
        <span class="n">xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># running average of the gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">chi</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">chi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chi</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># determine the new optimum shots distribution for the next</span>
        <span class="c1"># iteration of the optimizer</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
            <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">xi</span><span class="p">)</span>
            <span class="o">/</span> <span class="p">((</span><span class="mi">2</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">chi</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)))</span>
        <span class="p">)</span>

        <span class="c1"># apply an upper and lower bound on the new shot distributions,</span>
        <span class="c1"># to avoid the number of shots reducing below min(2, min_shots),</span>
        <span class="c1"># or growing too significantly.</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">chi</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="o">-</span> <span class="n">xi</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lipschitz</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">s</span>

        <span class="n">argmax_gamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">gamma</span><span class="p">),</span> <span class="n">gamma</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">smax</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">argmax_gamma</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_shots</span><span class="p">),</span> <span class="n">smax</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">params</span>
</pre></div>
</div>
</div>
<div class="section" id="rosalin-optimization">
<h3>Rosalin optimization<a class="headerlink" href="#rosalin-optimization" title="Permalink to this headline">¶</a></h3>
<p>We are now ready to use our Rosalin optimizer to optimize the initial VQE problem.
Note that we create our QNodes using <code class="docutils literal notranslate"><span class="pre">measure=&quot;sample&quot;</span></code>, since the Rosalin optimizer
must be able to generate single-shot samples from our device.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rosalin_device</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">num_wires</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.map.html#pennylane.map" title="pennylane.map" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">map</span></a><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.operation.Operation.html#pennylane.operation.Operation" title="pennylane.operation.Operation" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class"><span class="n">StronglyEntanglingLayers</span></a><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">rosalin_device</span><span class="p">,</span> <span class="n">measure</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s also create a separate cost function using an ‘exact’ quantum device, so that we can keep track of the
<em>exact</em> cost function value at each iteration.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cost_analytic</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.dot.html#pennylane.dot" title="pennylane.dot" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">dot</span></a><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.map.html#pennylane.map" title="pennylane.map" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">map</span></a><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.operation.Operation.html#pennylane.operation.Operation" title="pennylane.operation.Operation" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class"><span class="n">StronglyEntanglingLayers</span></a><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">analytic_dev</span><span class="p">))</span>
</pre></div>
</div>
<p>Creating the optimizer and beginning the optimization:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <span class="n">Rosalin</span><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html#pennylane.QNodeCollection" title="pennylane.QNodeCollection" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qnodes</span></a><span class="p">,</span> <span class="n">coeffs</span><span class="p">,</span> <span class="n">min_shots</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">init_params</span>

<span class="n">cost_rosalin</span> <span class="o">=</span> <span class="p">[</span><span class="n">cost_analytic</span><span class="p">(</span><span class="n">params</span><span class="p">)]</span>
<span class="n">shots_rosalin</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">60</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer.step" title="pennylane.AdamOptimizer.step" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-method"><span class="n">opt</span><span class="o">.</span><span class="n">step</span></a><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">cost_rosalin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_analytic</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
    <span class="n">shots_rosalin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span><span class="o">.</span><span class="n">shots_used</span></a><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: cost = </span><span class="si">{</span><span class="n">cost_rosalin</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, shots_used = </span><span class="si">{</span><span class="n">shots_rosalin</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Step 0: cost = -5.976611864639143, shots_used = 240
Step 1: cost = -3.9696542358660727, shots_used = 288
Step 2: cost = -4.960189727105254, shots_used = 360
Step 3: cost = -4.580003760087767, shots_used = 456
Step 4: cost = -2.230216749128693, shots_used = 552
Step 5: cost = -3.6390262209635624, shots_used = 696
Step 6: cost = -6.407579837465835, shots_used = 1050
Step 7: cost = -7.4366536874312565, shots_used = 1578
Step 8: cost = -7.259604321778904, shots_used = 2250
Step 9: cost = -7.062132684694287, shots_used = 2970
Step 10: cost = -7.5539381823528915, shots_used = 3738
Step 11: cost = -7.530120251217975, shots_used = 4866
Step 12: cost = -7.620064018172076, shots_used = 6474
Step 13: cost = -7.749105026853709, shots_used = 8288
Step 14: cost = -7.7584669100105454, shots_used = 10388
Step 15: cost = -7.547668090788587, shots_used = 12404
Step 16: cost = -7.802606000681813, shots_used = 14660
Step 17: cost = -7.819375105495885, shots_used = 17180
Step 18: cost = -7.813893056373781, shots_used = 19700
Step 19: cost = -7.818976697763795, shots_used = 22796
Step 20: cost = -7.847655565015213, shots_used = 26372
Step 21: cost = -7.854512274045721, shots_used = 30810
Step 22: cost = -7.855665819254089, shots_used = 35538
Step 23: cost = -7.843276666680198, shots_used = 40770
Step 24: cost = -7.82813895796069, shots_used = 45762
Step 25: cost = -7.796501914990248, shots_used = 51162
Step 26: cost = -7.871130124788932, shots_used = 56466
Step 27: cost = -7.866190872563943, shots_used = 62010
Step 28: cost = -7.780118268373553, shots_used = 68250
Step 29: cost = -7.843565291223448, shots_used = 74946
Step 30: cost = -7.840084824878835, shots_used = 81762
Step 31: cost = -7.863430860462219, shots_used = 88962
Step 32: cost = -7.863400771365601, shots_used = 96786
Step 33: cost = -7.828392469226825, shots_used = 104730
Step 34: cost = -7.845758777555817, shots_used = 114532
Step 35: cost = -7.862280441095794, shots_used = 122908
Step 36: cost = -7.866212335569502, shots_used = 131836
Step 37: cost = -7.859430128177042, shots_used = 140500
Step 38: cost = -7.856087432905534, shots_used = 150076
Step 39: cost = -7.850323433779115, shots_used = 159676
Step 40: cost = -7.834403598788763, shots_used = 170116
Step 41: cost = -7.849769789802028, shots_used = 181300
Step 42: cost = -7.86693841353118, shots_used = 192700
Step 43: cost = -7.865653895759861, shots_used = 204460
Step 44: cost = -7.853522061269157, shots_used = 217900
Step 45: cost = -7.885272132729725, shots_used = 231748
Step 46: cost = -7.88224395467864, shots_used = 245644
Step 47: cost = -7.884376349618622, shots_used = 259852
Step 48: cost = -7.8808911781003825, shots_used = 275164
Step 49: cost = -7.881035167671664, shots_used = 292444
Step 50: cost = -7.881931152903569, shots_used = 310300
Step 51: cost = -7.873486288144938, shots_used = 329452
Step 52: cost = -7.842973314288795, shots_used = 348532
Step 53: cost = -7.87101794797729, shots_used = 368644
Step 54: cost = -7.880857865087542, shots_used = 388828
Step 55: cost = -7.884163217633474, shots_used = 409132
Step 56: cost = -7.866452206380498, shots_used = 429076
Step 57: cost = -7.876255345278057, shots_used = 451468
Step 58: cost = -7.87369984074766, shots_used = 475348
Step 59: cost = -7.890243502630163, shots_used = 501460
</pre></div>
</div>
<p>Let’s compare this to a standard Adam optimization. Using 100 shots per quantum
evaluation, for each update step there are 2 quantum evaluations per parameter.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">adam_shots_per_eval</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">adam_shots_per_step</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">adam_shots_per_eval</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">adam_shots_per_step</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2400
</pre></div>
</div>
<p>Thus, Adam is using 2400 shots per update step.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">init_params</span>
<a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">AdamOptimizer</span></a><span class="p">(</span><span class="mf">0.07</span><span class="p">)</span>

<a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QubitDevice.html#pennylane.QubitDevice.shots" title="pennylane.QubitDevice.shots" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-attribute"><span class="n">non_analytic_dev</span><span class="o">.</span><span class="n">shots</span></a> <span class="o">=</span> <span class="n">adam_shots_per_eval</span>
<span class="n">cost</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.dot.html#pennylane.dot" title="pennylane.dot" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">dot</span></a><span class="p">(</span>
  <span class="n">coeffs</span><span class="p">,</span>
  <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.map.html#pennylane.map" title="pennylane.map" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">map</span></a><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.operation.Operation.html#pennylane.operation.Operation" title="pennylane.operation.Operation" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class"><span class="n">StronglyEntanglingLayers</span></a><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">non_analytic_dev</span><span class="p">,</span> <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;parameter-shift&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">cost_adam</span> <span class="o">=</span> <span class="p">[</span><span class="n">cost_analytic</span><span class="p">(</span><span class="n">params</span><span class="p">)]</span>
<span class="n">shots_adam</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer.step" title="pennylane.AdamOptimizer.step" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-method"><span class="n">opt</span><span class="o">.</span><span class="n">step</span></a><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">cost_adam</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_analytic</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
    <span class="n">shots_adam</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">adam_shots_per_step</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Step </span><span class="si">{}</span><span class="s2">: cost = </span><span class="si">{}</span><span class="s2"> shots_used = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost_adam</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">shots_adam</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Step 0: cost = -2.03376839972733 shots_used = 2400
Step 1: cost = -3.0397515887713897 shots_used = 4800
Step 2: cost = -3.8459175082365666 shots_used = 7200
Step 3: cost = -4.505506895275778 shots_used = 9600
Step 4: cost = -5.0488106623708084 shots_used = 12000
Step 5: cost = -5.482162129547712 shots_used = 14400
Step 6: cost = -5.83880726147689 shots_used = 16800
Step 7: cost = -6.143933494222608 shots_used = 19200
Step 8: cost = -6.412317130720796 shots_used = 21600
Step 9: cost = -6.6534666682698 shots_used = 24000
Step 10: cost = -6.86746547637287 shots_used = 26400
Step 11: cost = -7.057043661341395 shots_used = 28800
Step 12: cost = -7.219548494479429 shots_used = 31200
Step 13: cost = -7.3445177518694456 shots_used = 33600
Step 14: cost = -7.435753942420535 shots_used = 36000
Step 15: cost = -7.497138548636965 shots_used = 38400
Step 16: cost = -7.529946318655265 shots_used = 40800
Step 17: cost = -7.537070813893377 shots_used = 43200
Step 18: cost = -7.525225697166624 shots_used = 45600
Step 19: cost = -7.5048251159723405 shots_used = 48000
Step 20: cost = -7.481487171246212 shots_used = 50400
Step 21: cost = -7.461106527571478 shots_used = 52800
Step 22: cost = -7.4490325775024075 shots_used = 55200
Step 23: cost = -7.444817343084735 shots_used = 57600
Step 24: cost = -7.4494913586937574 shots_used = 60000
Step 25: cost = -7.462969617594349 shots_used = 62400
Step 26: cost = -7.484518392550573 shots_used = 64800
Step 27: cost = -7.509533957688121 shots_used = 67200
Step 28: cost = -7.535240804873656 shots_used = 69600
Step 29: cost = -7.560642729685874 shots_used = 72000
Step 30: cost = -7.586205677180162 shots_used = 74400
Step 31: cost = -7.61260475402048 shots_used = 76800
Step 32: cost = -7.637117815005769 shots_used = 79200
Step 33: cost = -7.661716123608457 shots_used = 81600
Step 34: cost = -7.6852319189727165 shots_used = 84000
Step 35: cost = -7.708583289744081 shots_used = 86400
Step 36: cost = -7.729551671925802 shots_used = 88800
Step 37: cost = -7.7462558125604595 shots_used = 91200
Step 38: cost = -7.758965992155235 shots_used = 93600
Step 39: cost = -7.764889692835303 shots_used = 96000
Step 40: cost = -7.770298814247658 shots_used = 98400
Step 41: cost = -7.771938304013664 shots_used = 100800
Step 42: cost = -7.771490419427766 shots_used = 103200
Step 43: cost = -7.771665932203987 shots_used = 105600
Step 44: cost = -7.771775966399097 shots_used = 108000
Step 45: cost = -7.772019786144459 shots_used = 110400
Step 46: cost = -7.774409408800273 shots_used = 112800
Step 47: cost = -7.777544198411677 shots_used = 115200
Step 48: cost = -7.78057842461007 shots_used = 117600
Step 49: cost = -7.7865146226898805 shots_used = 120000
Step 50: cost = -7.793839215454196 shots_used = 122400
Step 51: cost = -7.802144039740554 shots_used = 124800
Step 52: cost = -7.809859012081808 shots_used = 127200
Step 53: cost = -7.818330164675909 shots_used = 129600
Step 54: cost = -7.826930993976666 shots_used = 132000
Step 55: cost = -7.834969848723968 shots_used = 134400
Step 56: cost = -7.842454395123664 shots_used = 136800
Step 57: cost = -7.849335152675151 shots_used = 139200
Step 58: cost = -7.853951071633944 shots_used = 141600
Step 59: cost = -7.858296868696565 shots_used = 144000
Step 60: cost = -7.862867672169834 shots_used = 146400
Step 61: cost = -7.865540080202736 shots_used = 148800
Step 62: cost = -7.867577632485199 shots_used = 151200
Step 63: cost = -7.869035010771334 shots_used = 153600
Step 64: cost = -7.870496374034538 shots_used = 156000
Step 65: cost = -7.871678720443278 shots_used = 158400
Step 66: cost = -7.872542373444428 shots_used = 160800
Step 67: cost = -7.873739299675017 shots_used = 163200
Step 68: cost = -7.874314293738313 shots_used = 165600
Step 69: cost = -7.875793149514538 shots_used = 168000
Step 70: cost = -7.877051911492931 shots_used = 170400
Step 71: cost = -7.878207264678217 shots_used = 172800
Step 72: cost = -7.879198045006914 shots_used = 175200
Step 73: cost = -7.880726987471535 shots_used = 177600
Step 74: cost = -7.882055795432435 shots_used = 180000
Step 75: cost = -7.88215282515028 shots_used = 182400
Step 76: cost = -7.881947191378357 shots_used = 184800
Step 77: cost = -7.881566349945106 shots_used = 187200
Step 78: cost = -7.881659168988012 shots_used = 189600
Step 79: cost = -7.881276797156975 shots_used = 192000
Step 80: cost = -7.879976174007023 shots_used = 194400
Step 81: cost = -7.878714918643873 shots_used = 196800
Step 82: cost = -7.877964404670651 shots_used = 199200
Step 83: cost = -7.8771022016203665 shots_used = 201600
Step 84: cost = -7.875562772172711 shots_used = 204000
Step 85: cost = -7.875602350174969 shots_used = 206400
Step 86: cost = -7.877141380119034 shots_used = 208800
Step 87: cost = -7.87925788505365 shots_used = 211200
Step 88: cost = -7.881144761009377 shots_used = 213600
Step 89: cost = -7.882250363744701 shots_used = 216000
Step 90: cost = -7.881748113564451 shots_used = 218400
Step 91: cost = -7.883533319932514 shots_used = 220800
Step 92: cost = -7.884779159318079 shots_used = 223200
Step 93: cost = -7.8868911005436555 shots_used = 225600
Step 94: cost = -7.888524224480213 shots_used = 228000
Step 95: cost = -7.888123287772768 shots_used = 230400
Step 96: cost = -7.8867800801467896 shots_used = 232800
Step 97: cost = -7.8853107450636415 shots_used = 235200
Step 98: cost = -7.883507674089132 shots_used = 237600
Step 99: cost = -7.881351067687096 shots_used = 240000
</pre></div>
</div>
<p>Plotting both experiments:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;seaborn&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">shots_rosalin</span><span class="p">,</span> <span class="n">cost_rosalin</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Rosalin&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">shots_adam</span><span class="p">,</span> <span class="n">cost_adam</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost function value&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of shots&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">300000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="tutorial rosalin" class="sphx-glr-single-img" src="../_images/sphx_glr_tutorial_rosalin_002.png" />
<p>The Rosalin optimizer performs significantly better than the Adam optimizer,
approaching the ground state energy of the Hamiltonian with strikingly
fewer shots.</p>
<p>While beyond the scope of this demonstration, the Rosalin optimizer can be
modified in various other ways; for instance, by incorporating <em>weighted hybrid
sampling</em> (which distributes some shots deterministically, with the remainder
done randomly), or by adapting the variant iCANS2 optimizer. Download
this demonstration from the sidebar 👉 and give it a go! ⚛️</p>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<table class="docutils footnote" frame="void" id="arrasmith2020" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id5">2</a>, <a class="fn-backref" href="#id6">3</a>, <a class="fn-backref" href="#id7">4</a>)</em> Andrew Arrasmith, Lukasz Cincio, Rolando D. Somma, and Patrick J. Coles. “Operator Sampling
for Shot-frugal Optimization in Variational Algorithms.” <a class="reference external" href="https://arxiv.org/abs/2004.06252">arXiv:2004.06252</a> (2020).</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="stokes2019" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>James Stokes, Josh Izaac, Nathan Killoran, and Giuseppe Carleo. “Quantum Natural Gradient.”
<a class="reference external" href="https://arxiv.org/abs/1909.02108">arXiv:1909.02108</a> (2019).</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="sweke2019" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[3]</a></td><td>Ryan Sweke, Frederik Wilde, Johannes Jakob Meyer, Maria Schuld, Paul K. Fährmann, Barthélémy
Meynard-Piganeau, and Jens Eisert. “Stochastic gradient descent for hybrid quantum-classical
optimization.” <a class="reference external" href="https://arxiv.org/abs/1910.01155">arXiv:1910.01155</a> (2019).</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="kubler2020" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[4]</td><td><em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id8">2</a>)</em> Jonas M. Kübler, Andrew Arrasmith, Lukasz Cincio, and Patrick J. Coles. “An Adaptive Optimizer
for Measurement-Frugal Variational Algorithms.” <a class="reference external" href="https://quantum-journal.org/papers/q-2020-05-11-263/">Quantum 4, 263</a> (2020).</td></tr>
</tbody>
</table>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  49.081 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-rosalin-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<a class="reference download internal" download="" href="../_downloads/d2ea8ee97cdc680eec895dfb70cf95e8/tutorial_rosalin.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_rosalin.py</span></code></a></div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<a class="reference download internal" download="" href="../_downloads/8ad500bdf39b4ed589c41156e09bbfda/tutorial_rosalin.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_rosalin.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_rosalin</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>
            </div>
          </div>
              <div class="comment-container nano has-scrollbar">
  <div class="nano-content">
    
    <div id="comments">
      <h3>Contents</h3>
      <ul>
<li><a class="reference internal" href="#">Frugal shot optimization with Rosalin</a><ul>
<li><a class="reference internal" href="#background">Background</a></li>
<li><a class="reference internal" href="#weighted-random-sampling">Weighted random sampling</a></li>
<li><a class="reference internal" href="#rosalin-frugal-shot-optimization">Rosalin: Frugal shot optimization</a><ul>
<li><a class="reference internal" href="#icans-optimizer">iCANS optimizer</a></li>
<li><a class="reference internal" href="#rosalin-implementation">Rosalin implementation</a></li>
<li><a class="reference internal" href="#rosalin-optimization">Rosalin optimization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

    </div>
    
    <div class="xanadu-call-to-action-links">
      <h3>Downloads</h3>
      <div id="tutorial-type">demos/tutorial_rosalin</div>
      <div class="download-python-link">
        <i class="fab fa-python"></i>&nbsp;
        <div class="call-to-action-desktop-view">Download Python script</div>
      </div>
      <div class="download-notebook-link">
        <i class="fas fa-download"></i>&nbsp;
        <div class="call-to-action-desktop-view">Download Notebook</div>
      </div>
      <div class="github-view-link">
        <i class="fab fa-github"></i>&nbsp;
        <div class="call-to-action-desktop-view">View on GitHub</div>
      </div>
      <div id="related-tutorials" class="mt-4">
      <h3> Related tutorials</h3>
      </div>
    </div>
  </div>
</div>
            

          <div class="up-button">
            
              
                <a href="../demos_optimization.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>


    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial_falqon.html" title="Feedback-Based Quantum Optimization (FALQON)"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial_rotoselect.html" title="Quantum circuit structure learning"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_optimization.html" >Optimization</a> &#187;</li> 
      </ul>
    </div>

    <!-- JQuery -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <!-- Bootstrap core JavaScript -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
    <!-- MDB core JavaScript -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
    <!-- Nanoscroller -->
    <script type="text/javascript" src="../_static/js/nanoscroller.min.js"></script>
    <script type="text/javascript">
        $('a.reference.external').each(function(){
          var link = $(this).attr("href");
          var hash = link.split('#')[1];
          var page = link.split('#')[0].split('/').slice(-1)[0].replace(".html", "");
          if (hash == page) {
            $(this).attr('href', link.split('#')[0]);
          }
        });
        $(".document > .section").removeClass("section");
        var tocContainer = document.querySelector('.comment-container');
        tocContainer.style.height = '85vh';
        $(".nano").nanoScroller();
    </script>
    <!-- lightslider -->
    <script src="../_static/js/lightslider.min.js"></script>

    <script type="text/javascript">
      $(window).scroll(function(){
          var windowHeight = window.innerHeight;
          var footer = document.querySelector('.page-footer');
          var footerPosition = footer.getBoundingClientRect();
          var tocContainer = document.querySelector('.comment-container');

          // Check if the footer is visible
          if (footerPosition.top < windowHeight && footerPosition.bottom >= 0) {
              // We want the height of the TOC to be the height of the main content minus how much of the footer is visible.
              tocContainer.style.height = 'calc(85vh - 45px - ' + (windowHeight - footerPosition.top) + 'px)'
          } else {
            // When the user scrolls back to the top of the page after scrolling to the bottom of the page,
            // We want to reset the TOC container back to it's original height
            if (tocContainer.style.height !== '85vh') tocContainer.style.height = '85vh';
          }
      });
      $(document).ready(function () {
          $(".css-transitions-only-after-page-load").each(function (index, element) {
              setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
          });
      });
    </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "XanaduAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href,
          notebookDownloadPath = notebookLink.split('_downloads')[1].split('/').pop();

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();
      }
    </script>


    <script type="text/javascript">
        $(document).ready(function() {
            $("#featured-demos").lightSlider({
                item: 3,
                autoWidth: false,
                slideMove: 1, // slidemove will be 1 if loop is true
                slideMargin: 0,
                auto: true,
                loop: true,
                controls: true,
                pause: 5000,
                pager: false,
                prevHtml: "<i class='fas fa-chevron-left black-text' style='font-size: xx-large;'></i>",
                nextHtml: "<i class='fas fa-chevron-right black-text' style='font-size: xx-large;'></i>",
                responsive : [
                    {
                        breakpoint:1400,
                        settings: {
                            item:2,
                            slideMove:1,
                            slideMargin:0,
                          }
                    },
                    {
                        breakpoint:768,
                        settings: {
                            item:1,
                            slideMove:1,
                            slideMargin:6,
                          }
                    }
                ]
            });
        });
    </script>


  <footer class="page-footer text-md-left pt-4">
  
    <hr class="pb-0 mb-0">
    <div class="container-fluid">
      <div class="row   justify-content-md-center">
        <div class="col-md-3">
          <h5 class=" mb-1 footer-heading">Xanadu</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <p class="">Located in the heart of downtown Toronto, we've brought together exceptional minds from around the world to build quantum computers that are useful and available to people everywhere.</p>
        </div>

    <div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">PennyLane</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://pennylane.ai/">Home page</a></li>
            <li><a class="" href="https://github.com/XanaduAI/pennylane">GitHub</a></li>
            <li><a class="" href="https://pennylane.readthedocs.io/">Documentation</a></li>
            <li><a class="" href="https://discuss.pennylane.ai/">Discussion forum</a></li>
            <li><a class="" href="https://twitter.com/pennylaneai/">Twitter</a></li>
          </ul>
        </div>
		<div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">Strawberry Fields</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://strawberryfields.ai/">Interactive</a></li>
            <li><a class="" href="https://github.com/XanaduAI/strawberryfields">GitHub</a></li>
            <li><a class="" href="https://strawberryfields.readthedocs.io/">Documentation</a></li>
            <li><a class="" href="https://u.strawberryfields.ai/slack/">Slack channel</a></li>
          </ul>
        </div>


        <div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">About</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://www.xanadu.ai/">Home</a></li>
            <li><a class="" href="https://www.xanadu.ai/hardware/">Hardware</a></li>
            <li><a class="" href="https://www.xanadu.ai/software/">Software</a></li>
            <li><a class="" href="https://www.xanadu.ai/research">Research</a></li>
            <li><a class="" href="https://medium.com/XanaduAI">Blog</a></li>
            <li><a class="" href="https://www.xanadu.ai/about/">About</a></li>
          </ul>
        </div>
      </div>
    </div>
    <hr>

    <!-- <hr class="pb-0 mb-0"> -->

    <!--Social buttons-->
    <div class="social-section text-center">
        <ul class="list-unstyled list-inline mb-0">
            <li class="list-inline-item"><a class="btn-fb" href="https://www.facebook.com/Xanadu-1312050742230493/"><i class="fab fa-facebook-f"> </i></a></li>
            <li class="list-inline-item"><a class="btn-tw" href="https://twitter.com/xanaduai"><i class="fab fa-twitter"> </i></a></li>
            <li class="list-inline-item"><a class="" href="https://medium.com/xanaduai"><i class="fab fa-medium-m"> </i></a></li>
            <li class="list-inline-item"><a class="btn-li" href="https://www.linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
            <li class="list-inline-item"><a class="btn-git" href="https://github.com/XanaduAI"><i class="fab fa-github"> </i></a></li>
        </ul>
        <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">Stay updated with our newsletter</a>
    </div>
    <!--/.Social buttons-->

    <!--Copyright-->
    <div class="footer-copyright py-3 mt-0 text-center">
        <div class="container-fluid">
            © Copyright 2019 | Xanadu | All rights reserved
            <br>
             TensorFlow, the TensorFlow logo and any related marks are trademarks of Google Inc. 
        </div>
    </div>
  </footer>
  </body>
</html>
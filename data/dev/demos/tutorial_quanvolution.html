
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><meta content="Train a quantum convolutional neural network to classify MNIST images." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/circuit.png" property="og:image" />

  

  <meta property="og:title" content="Quanvolutional Neural Networks &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_quanvolution.html">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Train a quantum convolutional neural network to classify MNIST images." name="description" />
  

  <link href="https://fonts.googleapis.com/css?family=Noto+Serif" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Noto+Sans" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

  <!-- Material Design Bootstrap -->
  <!-- <link href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/css/mdb.min.css" rel="stylesheet"> -->

  <!-- nanoscroller -->
  <link rel="stylesheet" type="text/css" href="../_static/css/nanoscroller.css" />

  <!-- lightslider -->
  <link type="text/css" rel="stylesheet" href="../_static/css/lightslider.min.css" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       SVG: { linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           bm: ['\\mathbf{\#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['I',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           diag: ['\\mathrm{diag} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0]
         }
       }
     });
     </script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-130507810-1');
      </script>

  <title>Quanvolutional Neural Networks &#8212; PennyLane</title>
  
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/xanadu_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_quanvolution.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Multiclass margin classifier" href="tutorial_multiclass_classification.html" />
    <link rel="prev" title="Quantum transfer learning" href="tutorial_quantum_transfer_learning.html" /> 
  </head><body><link rel="stylesheet" type="text/css" href="../_static/xanadu_gallery.css" />
  <!--Navbar-->
<nav class="navbar navbar-expand-lg navbar-light white sticky-top">

  <!-- Navbar brand -->
  <a class="navbar-brand" href="https://pennylane.ai">
    <img class="pr-1" src="../_static/xanadu_x.png" width="28px"></img>
    <img src="../_static/pennylane.png" width="180px"></img>
  </a>

  <!-- Collapse button -->
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
    aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <!-- Collapsible content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links -->
    <ul class="navbar-nav mr-auto">
      <li class="nav-item active">
        <a class="nav-link" href="https://pennylane.ai/qml">Quantum machine learning
          <span class="sr-only">(current)</span>
        </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/install.html">Install</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/plugins.html">Plugins</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.readthedocs.io">Documentation</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/blog">Blog</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://qhack.ai"><img src="https://pennylane.ai/img/qhack_plain_black.png"></a>
      </li>
    </ul>
    <!-- Links -->

    <ul class="navbar-nav ml-auto nav-flex-icons">
      <li class="nav-item">
        <a class="nav-link" href="http://pennylane.ai/faq.html">
          <i class="fab fas fa-question"></i> FAQ
        </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://discuss.pennylane.ai">
          <i class="fab fab fa-discourse"></i> Support
        </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://github.com/XanaduAI/PennyLane">
          <i class="fab fa-github"></i> GitHub
        </a>
      </li>
    </ul>
  </div>
  <!-- Collapsible content -->
</nav>
<!--/.Navbar-->
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial_multiclass_classification.html" title="Multiclass margin classifier"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial_quantum_transfer_learning.html" title="Quantum transfer learning"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_research.html" accesskey="U">Research</a> &#187;</li> 
      </ul>
    </div>
        <div id="content">


          <div id="right-column">
            <div class="document clearer body">

              <div class="container-wrapper">

                <div role="navigation" aria-label="breadcrumbs navigation">
                  <ol class="breadcrumb">
                  </ol>
                </div>

              
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-demos-tutorial-quanvolution-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="quanvolutional-neural-networks">
<span id="quanvolution"></span><span id="sphx-glr-demos-tutorial-quanvolution-py"></span><h1>Quanvolutional Neural Networks<a class="headerlink" href="#quanvolutional-neural-networks" title="Permalink to this headline">¶</a></h1>
<p><em>Author: Andrea Mari. Last updated: 15 Jan 2021.</em></p>
<p>In this demo we implement the <em>Quanvolutional Neural Network</em>, a quantum
machine learning model originally introduced in
<a class="reference external" href="https://arxiv.org/abs/1904.04767">Henderson et al. (2019)</a>.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0)"><img alt="../_images/circuit2.png" src="../_images/circuit2.png" style="width: 90%;" /></a>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classical-convolution">
<h3>Classical convolution<a class="headerlink" href="#classical-convolution" title="Permalink to this headline">¶</a></h3>
<p>The <em>convolutional neural network</em> (CNN) is a standard model in classical machine learning which is particularly
suitable for processing images.
The model is based on the idea of a <em>convolution layer</em> where, instead of processing the full input data with a global function,
a local convolution is applied.</p>
<p>If the input is an image, small local regions are sequentially processed with the same kernel. The results obtained for each region are usually associated to different channels
of a single output pixel. The union of all the output pixels produces a new image-like object, which can be further processed by
additional layers.</p>
</div>
<div class="section" id="quantum-convolution">
<h3>Quantum convolution<a class="headerlink" href="#quantum-convolution" title="Permalink to this headline">¶</a></h3>
<p>One can extend the same idea also to the context of quantum variational circuits. A possible approach is given
by the following procedure which is very similar to the one used in Ref. [1]. The scheme is also represented in the
figure at the top of this tutorial.</p>
<ol class="arabic simple">
<li>A small region of the input image, in our example a <span class="math notranslate nohighlight">\(2 \times 2\)</span> square, is embedded into a quantum circuit.
In this demo, this is achieved with parametrized rotations applied to the qubits initialized in the ground state.</li>
<li>A quantum computation, associated to a unitary <span class="math notranslate nohighlight">\(U\)</span>, is performed on the system.
The unitary could be generated by a variational quantum circuit or, more simply, by a random circuit as
proposed in Ref. [1].</li>
<li>The quantum system is finally measured, obtaining a list of classical expectation values.
The measurement results could also be classically post-processed as proposed in Ref. [1] but, for simplicity, in this
demo we directly use the raw expectation values.</li>
<li>Analogously to a classical convolution layer, each expectation value is mapped to a different channel of a
single output pixel.</li>
<li>Iterating the same procedure over different regions, one can scan the full input image,
producing an output object which will be structured as a multi-channel image.</li>
<li>The quantum convolution can be followed by further quantum layers or by classical layers.</li>
</ol>
<p>The main difference with respect to a classical convolution is that a quantum circuit can
generate highly complex kernels whose computation could be, at least in principle, classically intractable.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In this tutorial we follow the approach of Ref. [1] in which a fixed non-trainable quantum
circuit is used as a “quanvolution” kernel, while the subsequent classical layers
are trained for the classification problem of interest.
However, by leveraging the ability of PennyLane to evaluate gradients of
quantum circuits, the quantum kernel could also be trained.</p>
</div>
</div>
</div>
<div class="section" id="general-setup">
<h2>General setup<a class="headerlink" href="#general-setup" title="Permalink to this headline">¶</a></h2>
<p>This Python code requires <em>PennyLane</em> with the <em>TensorFlow</em> interface and the plotting library <em>matplotlib</em>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">pennylane.templates</span> <span class="kn">import</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.operation.Operation.html#pennylane.operation.Operation" title="pennylane.operation.Operation" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class"><span class="n">RandomLayers</span></a>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
<div class="section" id="setting-of-the-main-hyper-parameters-of-the-model">
<h3>Setting of the main hyper-parameters of the model<a class="headerlink" href="#setting-of-the-main-hyper-parameters-of-the-model" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">30</span>   <span class="c1"># Number of optimization epochs</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># Number of random layers</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">50</span>    <span class="c1"># Size of the train dataset</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="mi">30</span>     <span class="c1"># Size of the test dataset</span>

<span class="n">SAVE_PATH</span> <span class="o">=</span> <span class="s2">&quot;quanvolution/&quot;</span> <span class="c1"># Data saving folder</span>
<span class="n">PREPROCESS</span> <span class="o">=</span> <span class="kc">True</span>           <span class="c1"># If False, skip quantum processing and load data from SAVE_PATH</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>           <span class="c1"># Seed for NumPy random number generator</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>       <span class="c1"># Seed for TensorFlow random number generator</span>
</pre></div>
</div>
</div>
<div class="section" id="loading-of-the-mnist-dataset">
<h3>Loading of the MNIST dataset<a class="headerlink" href="#loading-of-the-mnist-dataset" title="Permalink to this headline">¶</a></h3>
<p>We import the MNIST dataset from <em>Keras</em>. To speedup the evaluation of this demo
we use only a small number of training and test images. Obviously, better
results are achievable when using the full dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist_dataset</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Reduce dataset size</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">test_labels</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>

<span class="c1"># Normalize pixel values within 0 and 1</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span> <span class="o">/</span> <span class="mi">255</span>

<span class="c1"># Add extra dimension for convolution channels</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_images</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_images</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz

    8192/11490434 [..............................] - ETA: 0s
 7651328/11490434 [==================&gt;...........] - ETA: 0s
11493376/11490434 [==============================] - 0s 0us/step
</pre></div>
</div>
</div>
</div>
<div class="section" id="quantum-circuit-as-a-convolution-kernel">
<h2>Quantum circuit as a convolution kernel<a class="headerlink" href="#quantum-circuit-as-a-convolution-kernel" title="Permalink to this headline">¶</a></h2>
<p>We follow the scheme described in the introduction and represented in the figure at the top
of this demo.</p>
<p>We initialize a PennyLane <code class="docutils literal notranslate"><span class="pre">default.qubit</span></code> device, simulating a system of <span class="math notranslate nohighlight">\(4\)</span> qubits.
The associated <code class="docutils literal notranslate"><span class="pre">qnode</span></code> represents the quantum circuit consisting of:</p>
<ol class="arabic simple">
<li>an embedding layer of local <span class="math notranslate nohighlight">\(R_y\)</span> rotations (with angles scaled by a factor of <span class="math notranslate nohighlight">\(\pi\)</span>);</li>
<li>a random circuit of <code class="docutils literal notranslate"><span class="pre">n_layers</span></code>;</li>
<li>a final measurement in the computational basis, estimating <span class="math notranslate nohighlight">\(4\)</span> expectation values.</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dev</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1"># Random circuit parameters</span>
<span class="n">rand_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">high</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_layers</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">circuit</span><span class="p">(</span><span class="n">phi</span><span class="p">):</span>
    <span class="c1"># Encoding of 4 classical input values</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.RY.html#pennylane.RY" title="pennylane.RY" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">RY</span></a><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="n">j</span><span class="p">)</span>

    <span class="c1"># Random quantum circuit</span>
    <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.operation.Operation.html#pennylane.operation.Operation" title="pennylane.operation.Operation" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class"><span class="n">RandomLayers</span></a><span class="p">(</span><span class="n">rand_params</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)))</span>

    <span class="c1"># Measurement producing 4 classical output values</span>
    <span class="k">return</span> <span class="p">[</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="n">j</span><span class="p">))</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
</pre></div>
</div>
<p>The next function defines the convolution scheme:</p>
<ol class="arabic simple">
<li>the image is divided into squares of <span class="math notranslate nohighlight">\(2 \times 2\)</span> pixels;</li>
<li>each square is processed by the quantum circuit;</li>
<li>the <span class="math notranslate nohighlight">\(4\)</span> expectation values are mapped into <span class="math notranslate nohighlight">\(4\)</span> different
channels of a single output pixel.</li>
</ol>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This process halves the resolution of the input image. In the
standard language of CNN, this would correspond to a convolution
with a <span class="math notranslate nohighlight">\(2 \times 2\)</span> <em>kernel</em> and a <em>stride</em> equal to <span class="math notranslate nohighlight">\(2\)</span>.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">quanv</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convolves the input image with many applications of the same quantum circuit.&quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="c1"># Loop over the coordinates of the top-left pixel of 2X2 squares</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
            <span class="c1"># Process a squared 2x2 region of the image with a quantum circuit</span>
            <span class="n">q_results</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">image</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">image</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">image</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">image</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="c1"># Assign expectation values to different channels of the output pixel (j/2, k/2)</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="n">out</span><span class="p">[</span><span class="n">j</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">k</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">q_results</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<div class="section" id="quantum-pre-processing-of-the-dataset">
<h3>Quantum pre-processing of the dataset<a class="headerlink" href="#quantum-pre-processing-of-the-dataset" title="Permalink to this headline">¶</a></h3>
<p>Since we are not going to train the quantum convolution layer, it is more
efficient to apply it as a “pre-processing” layer to all the images of our dataset.
Later an entirely classical model will be directly trained and tested on the
pre-processed dataset, avoiding unnecessary repetitions of quantum computations.</p>
<p>The pre-processed images will be saved in the folder <code class="docutils literal notranslate"><span class="pre">SAVE_PATH</span></code>.
Once saved, they can be directly loaded by setting <code class="docutils literal notranslate"><span class="pre">PREPROCESS</span> <span class="pre">=</span> <span class="pre">False</span></code>,
otherwise the quantum convolution is evaluated at each run of the code.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">PREPROCESS</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">q_train_images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Quantum pre-processing of train images:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_images</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2">        &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_train</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">q_train_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quanv</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
    <span class="n">q_train_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">q_train_images</span><span class="p">)</span>

    <span class="n">q_test_images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Quantum pre-processing of test images:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_images</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2">        &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_test</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">q_test_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quanv</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
    <span class="n">q_test_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">q_test_images</span><span class="p">)</span>

    <span class="c1"># Save pre-processed images</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">SAVE_PATH</span> <span class="o">+</span> <span class="s2">&quot;q_train_images.npy&quot;</span><span class="p">,</span> <span class="n">q_train_images</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">SAVE_PATH</span> <span class="o">+</span> <span class="s2">&quot;q_test_images.npy&quot;</span><span class="p">,</span> <span class="n">q_test_images</span><span class="p">)</span>


<span class="c1"># Load pre-processed images</span>
<span class="n">q_train_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SAVE_PATH</span> <span class="o">+</span> <span class="s2">&quot;q_train_images.npy&quot;</span><span class="p">)</span>
<span class="n">q_test_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SAVE_PATH</span> <span class="o">+</span> <span class="s2">&quot;q_test_images.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Quantum pre-processing of train images:
1/50
2/50
3/50
4/50
5/50
6/50
7/50
8/50
9/50
10/50
11/50
12/50
13/50
14/50
15/50
16/50
17/50
18/50
19/50
20/50
21/50
22/50
23/50
24/50
25/50
26/50
27/50
28/50
29/50
30/50
31/50
32/50
33/50
34/50
35/50
36/50
37/50
38/50
39/50
40/50
41/50
42/50
43/50
44/50
45/50
46/50
47/50
48/50
49/50
50/50
Quantum pre-processing of test images:
1/30
2/30
3/30
4/30
5/30
6/30
7/30
8/30
9/30
10/30
11/30
12/30
13/30
14/30
15/30
16/30
17/30
18/30
19/30
20/30
21/30
22/30
23/30
24/30
25/30
26/30
27/30
28/30
29/30
30/30
</pre></div>
</div>
<p>Let us visualize the effect of the quantum convolution
layer on a batch of samples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_channels</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Input&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_images</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>

    <span class="c1"># Plot all output channels</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_channels</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">c</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Output [ch. </span><span class="si">{}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">c</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">q_train_images</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="tutorial quanvolution" class="sphx-glr-single-img" src="../_images/sphx_glr_tutorial_quanvolution_001.png" />
<p>Below each input image, the <span class="math notranslate nohighlight">\(4\)</span> output channels generated by the
quantum convolution are visualized in gray scale.</p>
<p>One can clearly notice the downsampling of the resolution and
some local distortion introduced by the quantum kernel.
On the other hand the global shape of the image is preserved,
as expected for a convolution layer.</p>
</div>
</div>
<div class="section" id="hybrid-quantum-classical-model">
<h2>Hybrid quantum-classical model<a class="headerlink" href="#hybrid-quantum-classical-model" title="Permalink to this headline">¶</a></h2>
<p>After the application of the quantum convolution layer we feed the resulting
features into a classical neural network that will be trained to classify
the <span class="math notranslate nohighlight">\(10\)</span> different digits of the MNIST dataset.</p>
<p>We use a very simple model: just a fully connected layer with
10 output nodes with a final <em>softmax</em> activation function.</p>
<p>The model is compiled with a <em>stochastic-gradient-descent</em> optimizer,
and a <em>cross-entropy</em> loss function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">MyModel</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Initializes and returns a custom Keras model</span>
<span class="sd">    which is ready to be trained.&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>We first initialize an instance of the model, then we train and validate
it with the dataset that has been already pre-processed by a quantum convolution.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">q_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

<span class="n">q_history</span> <span class="o">=</span> <span class="n">q_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">q_train_images</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">q_test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
13/13 - 0s - loss: 3.0160 - accuracy: 0.1000 - val_loss: 2.0646 - val_accuracy: 0.2000
Epoch 2/30
13/13 - 0s - loss: 2.2510 - accuracy: 0.1800 - val_loss: 1.9801 - val_accuracy: 0.3333
Epoch 3/30
13/13 - 0s - loss: 1.7851 - accuracy: 0.4000 - val_loss: 1.8177 - val_accuracy: 0.2667
Epoch 4/30
13/13 - 0s - loss: 1.3652 - accuracy: 0.5400 - val_loss: 1.6107 - val_accuracy: 0.4667
Epoch 5/30
13/13 - 0s - loss: 1.1317 - accuracy: 0.7800 - val_loss: 1.4723 - val_accuracy: 0.6000
Epoch 6/30
13/13 - 0s - loss: 0.9360 - accuracy: 0.8600 - val_loss: 1.4686 - val_accuracy: 0.5333
Epoch 7/30
13/13 - 0s - loss: 0.7383 - accuracy: 0.9400 - val_loss: 1.3536 - val_accuracy: 0.5667
Epoch 8/30
13/13 - 0s - loss: 0.5846 - accuracy: 0.9800 - val_loss: 1.2785 - val_accuracy: 0.6667
Epoch 9/30
13/13 - 0s - loss: 0.4987 - accuracy: 0.9800 - val_loss: 1.2253 - val_accuracy: 0.6333
Epoch 10/30
13/13 - 0s - loss: 0.3921 - accuracy: 1.0000 - val_loss: 1.2655 - val_accuracy: 0.6333
Epoch 11/30
13/13 - 0s - loss: 0.3617 - accuracy: 1.0000 - val_loss: 1.1555 - val_accuracy: 0.7000
Epoch 12/30
13/13 - 0s - loss: 0.3078 - accuracy: 1.0000 - val_loss: 1.2107 - val_accuracy: 0.6667
Epoch 13/30
13/13 - 0s - loss: 0.2618 - accuracy: 1.0000 - val_loss: 1.1166 - val_accuracy: 0.7333
Epoch 14/30
13/13 - 0s - loss: 0.2463 - accuracy: 1.0000 - val_loss: 1.0624 - val_accuracy: 0.7000
Epoch 15/30
13/13 - 0s - loss: 0.2033 - accuracy: 1.0000 - val_loss: 1.0904 - val_accuracy: 0.7333
Epoch 16/30
13/13 - 0s - loss: 0.1799 - accuracy: 1.0000 - val_loss: 1.0865 - val_accuracy: 0.7333
Epoch 17/30
13/13 - 0s - loss: 0.1682 - accuracy: 1.0000 - val_loss: 1.0385 - val_accuracy: 0.7333
Epoch 18/30
13/13 - 0s - loss: 0.1484 - accuracy: 1.0000 - val_loss: 1.0676 - val_accuracy: 0.7000
Epoch 19/30
13/13 - 0s - loss: 0.1349 - accuracy: 1.0000 - val_loss: 1.0447 - val_accuracy: 0.7000
Epoch 20/30
13/13 - 0s - loss: 0.1255 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.7333
Epoch 21/30
13/13 - 0s - loss: 0.1135 - accuracy: 1.0000 - val_loss: 1.0451 - val_accuracy: 0.7333
Epoch 22/30
13/13 - 0s - loss: 0.1041 - accuracy: 1.0000 - val_loss: 1.0142 - val_accuracy: 0.7333
Epoch 23/30
13/13 - 0s - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.7333
Epoch 24/30
13/13 - 0s - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.7000
Epoch 25/30
13/13 - 0s - loss: 0.0868 - accuracy: 1.0000 - val_loss: 0.9715 - val_accuracy: 0.7333
Epoch 26/30
13/13 - 0s - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.7333
Epoch 27/30
13/13 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.7333
Epoch 28/30
13/13 - 0s - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.9570 - val_accuracy: 0.7667
Epoch 29/30
13/13 - 0s - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.9895 - val_accuracy: 0.7333
Epoch 30/30
13/13 - 0s - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.7333
</pre></div>
</div>
<p>In order to compare the results achievable with and without the quantum convolution layer,
we initialize also a “classical” instance of the model that will be directly trained
and validated with the raw MNIST images (i.e., without quantum pre-processing).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">c_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

<span class="n">c_history</span> <span class="o">=</span> <span class="n">c_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_images</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
13/13 - 0s - loss: 2.3619 - accuracy: 0.1400 - val_loss: 2.0567 - val_accuracy: 0.3667
Epoch 2/30
13/13 - 0s - loss: 1.9696 - accuracy: 0.4200 - val_loss: 1.9381 - val_accuracy: 0.4667
Epoch 3/30
13/13 - 0s - loss: 1.6671 - accuracy: 0.6400 - val_loss: 1.8300 - val_accuracy: 0.4333
Epoch 4/30
13/13 - 0s - loss: 1.4340 - accuracy: 0.7400 - val_loss: 1.7113 - val_accuracy: 0.4333
Epoch 5/30
13/13 - 0s - loss: 1.2342 - accuracy: 0.7600 - val_loss: 1.6044 - val_accuracy: 0.5000
Epoch 6/30
13/13 - 0s - loss: 1.0721 - accuracy: 0.8600 - val_loss: 1.5232 - val_accuracy: 0.5333
Epoch 7/30
13/13 - 0s - loss: 0.9348 - accuracy: 0.9000 - val_loss: 1.4596 - val_accuracy: 0.5667
Epoch 8/30
13/13 - 0s - loss: 0.8178 - accuracy: 0.9200 - val_loss: 1.3921 - val_accuracy: 0.6000
Epoch 9/30
13/13 - 0s - loss: 0.7223 - accuracy: 0.9400 - val_loss: 1.3404 - val_accuracy: 0.6333
Epoch 10/30
13/13 - 0s - loss: 0.6404 - accuracy: 0.9600 - val_loss: 1.3065 - val_accuracy: 0.6667
Epoch 11/30
13/13 - 0s - loss: 0.5772 - accuracy: 1.0000 - val_loss: 1.2644 - val_accuracy: 0.6333
Epoch 12/30
13/13 - 0s - loss: 0.5199 - accuracy: 1.0000 - val_loss: 1.2558 - val_accuracy: 0.6667
Epoch 13/30
13/13 - 0s - loss: 0.4695 - accuracy: 1.0000 - val_loss: 1.2258 - val_accuracy: 0.6667
Epoch 14/30
13/13 - 0s - loss: 0.4238 - accuracy: 1.0000 - val_loss: 1.1897 - val_accuracy: 0.6667
Epoch 15/30
13/13 - 0s - loss: 0.3848 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.6667
Epoch 16/30
13/13 - 0s - loss: 0.3525 - accuracy: 1.0000 - val_loss: 1.1503 - val_accuracy: 0.7333
Epoch 17/30
13/13 - 0s - loss: 0.3245 - accuracy: 1.0000 - val_loss: 1.1374 - val_accuracy: 0.7000
Epoch 18/30
13/13 - 0s - loss: 0.2992 - accuracy: 1.0000 - val_loss: 1.1174 - val_accuracy: 0.6667
Epoch 19/30
13/13 - 0s - loss: 0.2745 - accuracy: 1.0000 - val_loss: 1.1119 - val_accuracy: 0.6667
Epoch 20/30
13/13 - 0s - loss: 0.2551 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.7000
Epoch 21/30
13/13 - 0s - loss: 0.2370 - accuracy: 1.0000 - val_loss: 1.0877 - val_accuracy: 0.6667
Epoch 22/30
13/13 - 0s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.0776 - val_accuracy: 0.6667
Epoch 23/30
13/13 - 0s - loss: 0.2050 - accuracy: 1.0000 - val_loss: 1.0675 - val_accuracy: 0.7000
Epoch 24/30
13/13 - 0s - loss: 0.1919 - accuracy: 1.0000 - val_loss: 1.0592 - val_accuracy: 0.7000
Epoch 25/30
13/13 - 0s - loss: 0.1812 - accuracy: 1.0000 - val_loss: 1.0554 - val_accuracy: 0.6667
Epoch 26/30
13/13 - 0s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 1.0477 - val_accuracy: 0.7000
Epoch 27/30
13/13 - 0s - loss: 0.1599 - accuracy: 1.0000 - val_loss: 1.0377 - val_accuracy: 0.7000
Epoch 28/30
13/13 - 0s - loss: 0.1515 - accuracy: 1.0000 - val_loss: 1.0341 - val_accuracy: 0.6667
Epoch 29/30
13/13 - 0s - loss: 0.1426 - accuracy: 1.0000 - val_loss: 1.0291 - val_accuracy: 0.7000
Epoch 30/30
13/13 - 0s - loss: 0.1344 - accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 0.7000
</pre></div>
</div>
</div>
<div class="section" id="results">
<h3>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h3>
<p>We can finally plot the test accuracy and the test loss with respect to the
number of training epochs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;seaborn&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">q_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">],</span> <span class="s2">&quot;-ob&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;With quantum layer&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">],</span> <span class="s2">&quot;-og&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Without quantum layer&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">q_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="s2">&quot;-ob&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;With quantum layer&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="s2">&quot;-og&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Without quantum layer&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="tutorial quanvolution" class="sphx-glr-single-img" src="../_images/sphx_glr_tutorial_quanvolution_002.png" />
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>Maxwell Henderson, Samriddhi Shakya, Shashindra Pradhan, Tristan Cook.
“Quanvolutional Neural Networks: Powering Image Recognition with Quantum Circuits.”
<a class="reference external" href="https://arxiv.org/abs/1904.04767">arXiv:1904.04767</a>, 2019.</li>
</ol>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  28.605 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-quanvolution-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<a class="reference download internal" download="" href="../_downloads/e1d1052907393319a3eb4b8c092a3fc4/tutorial_quanvolution.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_quanvolution.py</span></code></a></div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<a class="reference download internal" download="" href="../_downloads/9492691e1c271ec98198344a9c4a9193/tutorial_quanvolution.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_quanvolution.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_quanvolution</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>
            </div>
          </div>
              <div class="comment-container nano has-scrollbar">
  <div class="nano-content">
    
    <div id="comments">
      <h3>Contents</h3>
      <ul>
<li><a class="reference internal" href="#">Quanvolutional Neural Networks</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a><ul>
<li><a class="reference internal" href="#classical-convolution">Classical convolution</a></li>
<li><a class="reference internal" href="#quantum-convolution">Quantum convolution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#general-setup">General setup</a><ul>
<li><a class="reference internal" href="#setting-of-the-main-hyper-parameters-of-the-model">Setting of the main hyper-parameters of the model</a></li>
<li><a class="reference internal" href="#loading-of-the-mnist-dataset">Loading of the MNIST dataset</a></li>
</ul>
</li>
<li><a class="reference internal" href="#quantum-circuit-as-a-convolution-kernel">Quantum circuit as a convolution kernel</a><ul>
<li><a class="reference internal" href="#quantum-pre-processing-of-the-dataset">Quantum pre-processing of the dataset</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hybrid-quantum-classical-model">Hybrid quantum-classical model</a><ul>
<li><a class="reference internal" href="#training">Training</a></li>
<li><a class="reference internal" href="#results">Results</a></li>
</ul>
</li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

    </div>
    
    <div class="xanadu-call-to-action-links">
      <h3>Downloads</h3>
      <div id="tutorial-type">demos/tutorial_quanvolution</div>
      <div class="download-python-link">
        <i class="fab fa-python"></i>&nbsp;
        <div class="call-to-action-desktop-view">Download Python script</div>
      </div>
      <div class="download-notebook-link">
        <i class="fas fa-download"></i>&nbsp;
        <div class="call-to-action-desktop-view">Download Notebook</div>
      </div>
      <div class="github-view-link">
        <i class="fab fa-github"></i>&nbsp;
        <div class="call-to-action-desktop-view">View on GitHub</div>
      </div>
      <div id="related-tutorials" class="mt-4">
      <h3> Related tutorials</h3>
      </div>
    </div>
  </div>
</div>
            

          <div class="up-button">
            
              
                <a href="../demos_research.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>


    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial_multiclass_classification.html" title="Multiclass margin classifier"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial_quantum_transfer_learning.html" title="Quantum transfer learning"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_research.html" >Research</a> &#187;</li> 
      </ul>
    </div>

    <!-- JQuery -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <!-- Bootstrap core JavaScript -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
    <!-- MDB core JavaScript -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
    <!-- Nanoscroller -->
    <script type="text/javascript" src="../_static/js/nanoscroller.min.js"></script>
    <script type="text/javascript">
        $('a.reference.external').each(function(){
          var link = $(this).attr("href");
          var hash = link.split('#')[1];
          var page = link.split('#')[0].split('/').slice(-1)[0].replace(".html", "");
          if (hash == page) {
            $(this).attr('href', link.split('#')[0]);
          }
        });
        $(".document > .section").removeClass("section");
        var tocContainer = document.querySelector('.comment-container');
        tocContainer.style.height = '85vh';
        $(".nano").nanoScroller();
    </script>
    <!-- lightslider -->
    <script src="../_static/js/lightslider.min.js"></script>

    <script type="text/javascript">
      $(window).scroll(function(){
          var windowHeight = window.innerHeight;
          var footer = document.querySelector('.page-footer');
          var footerPosition = footer.getBoundingClientRect();
          var tocContainer = document.querySelector('.comment-container');

          // Check if the footer is visible
          if (footerPosition.top < windowHeight && footerPosition.bottom >= 0) {
              // We want the height of the TOC to be the height of the main content minus how much of the footer is visible.
              tocContainer.style.height = 'calc(85vh - 45px - ' + (windowHeight - footerPosition.top) + 'px)'
          } else {
            // When the user scrolls back to the top of the page after scrolling to the bottom of the page,
            // We want to reset the TOC container back to it's original height
            if (tocContainer.style.height !== '85vh') tocContainer.style.height = '85vh';
          }
      });
      $(document).ready(function () {
          $(".css-transitions-only-after-page-load").each(function (index, element) {
              setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
          });
      });
    </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "XanaduAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href,
          notebookDownloadPath = notebookLink.split('_downloads')[1].split('/').pop();

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();
      }
    </script>


    <script type="text/javascript">
        $(document).ready(function() {
            $("#featured-demos").lightSlider({
                item: 3,
                autoWidth: false,
                slideMove: 1, // slidemove will be 1 if loop is true
                slideMargin: 0,
                auto: true,
                loop: true,
                controls: true,
                pause: 5000,
                pager: false,
                prevHtml: "<i class='fas fa-chevron-left black-text' style='font-size: xx-large;'></i>",
                nextHtml: "<i class='fas fa-chevron-right black-text' style='font-size: xx-large;'></i>",
                responsive : [
                    {
                        breakpoint:1400,
                        settings: {
                            item:2,
                            slideMove:1,
                            slideMargin:0,
                          }
                    },
                    {
                        breakpoint:768,
                        settings: {
                            item:1,
                            slideMove:1,
                            slideMargin:6,
                          }
                    }
                ]
            });
        });
    </script>


  <footer class="page-footer text-md-left pt-4">
  
    <hr class="pb-0 mb-0">
    <div class="container-fluid">
      <div class="row   justify-content-md-center">
        <div class="col-md-3">
          <h5 class=" mb-1 footer-heading">Xanadu</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <p class="">Located in the heart of downtown Toronto, we've brought together exceptional minds from around the world to build quantum computers that are useful and available to people everywhere.</p>
        </div>

    <div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">PennyLane</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://pennylane.ai/">Home page</a></li>
            <li><a class="" href="https://github.com/XanaduAI/pennylane">GitHub</a></li>
            <li><a class="" href="https://pennylane.readthedocs.io/">Documentation</a></li>
            <li><a class="" href="https://discuss.pennylane.ai/">Discussion forum</a></li>
            <li><a class="" href="https://twitter.com/pennylaneai/">Twitter</a></li>
          </ul>
        </div>
		<div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">Strawberry Fields</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://strawberryfields.ai/">Interactive</a></li>
            <li><a class="" href="https://github.com/XanaduAI/strawberryfields">GitHub</a></li>
            <li><a class="" href="https://strawberryfields.readthedocs.io/">Documentation</a></li>
            <li><a class="" href="https://u.strawberryfields.ai/slack/">Slack channel</a></li>
          </ul>
        </div>


        <div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">About</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://www.xanadu.ai/">Home</a></li>
            <li><a class="" href="https://www.xanadu.ai/hardware/">Hardware</a></li>
            <li><a class="" href="https://www.xanadu.ai/software/">Software</a></li>
            <li><a class="" href="https://www.xanadu.ai/research">Research</a></li>
            <li><a class="" href="https://medium.com/XanaduAI">Blog</a></li>
            <li><a class="" href="https://www.xanadu.ai/about/">About</a></li>
          </ul>
        </div>
      </div>
    </div>
    <hr>

    <!-- <hr class="pb-0 mb-0"> -->

    <!--Social buttons-->
    <div class="social-section text-center">
        <ul class="list-unstyled list-inline mb-0">
            <li class="list-inline-item"><a class="btn-fb" href="https://www.facebook.com/Xanadu-1312050742230493/"><i class="fab fa-facebook-f"> </i></a></li>
            <li class="list-inline-item"><a class="btn-tw" href="https://twitter.com/xanaduai"><i class="fab fa-twitter"> </i></a></li>
            <li class="list-inline-item"><a class="" href="https://medium.com/xanaduai"><i class="fab fa-medium-m"> </i></a></li>
            <li class="list-inline-item"><a class="btn-li" href="https://www.linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
            <li class="list-inline-item"><a class="btn-git" href="https://github.com/XanaduAI"><i class="fab fa-github"> </i></a></li>
        </ul>
        <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">Stay updated with our newsletter</a>
    </div>
    <!--/.Social buttons-->

    <!--Copyright-->
    <div class="footer-copyright py-3 mt-0 text-center">
        <div class="container-fluid">
            © Copyright 2019 | Xanadu | All rights reserved
            <br>
             TensorFlow, the TensorFlow logo and any related marks are trademarks of Google Inc. 
        </div>
    </div>
  </footer>
  </body>
</html>
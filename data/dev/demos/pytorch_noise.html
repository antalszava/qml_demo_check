
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><meta content="Extend PyTorch with real quantum computing power, by using it to optimize a noisy quantum hardware device." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/bloch.gif" property="og:image" />

  

  <meta property="og:title" content="PyTorch and noisy devices &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/pytorch_noise.html">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Extend PyTorch with real quantum computing power, by using it to optimize a noisy quantum hardware device." name="description" />
  

  <link href="https://fonts.googleapis.com/css?family=Noto+Serif" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Noto+Sans" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

  <!-- Material Design Bootstrap -->
  <!-- <link href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/css/mdb.min.css" rel="stylesheet"> -->

  <!-- nanoscroller -->
  <link rel="stylesheet" type="text/css" href="../_static/css/nanoscroller.css" />

  <!-- lightslider -->
  <link type="text/css" rel="stylesheet" href="../_static/css/lightslider.min.css" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       SVG: { linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           bm: ['\\mathbf{\#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['I',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           diag: ['\\mathrm{diag} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0]
         }
       }
     });
     </script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-130507810-1');
      </script>

  <title>PyTorch and noisy devices &#8212; PennyLane</title>
  
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/xanadu_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/pytorch_noise.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Optimizing noisy circuits with Cirq" href="tutorial_noisy_circuit_optimization.html" />
    <link rel="prev" title="3-qubit Ising model in PyTorch" href="tutorial_isingmodel_PyTorch.html" /> 
  </head><body><link rel="stylesheet" type="text/css" href="../_static/xanadu_gallery.css" />
  <!--Navbar-->
<nav class="navbar navbar-expand-lg navbar-light white sticky-top">

  <!-- Navbar brand -->
  <a class="navbar-brand" href="https://pennylane.ai">
    <img class="pr-1" src="../_static/xanadu_x.png" width="28px"></img>
    <img src="../_static/pennylane.png" width="180px"></img>
  </a>

  <!-- Collapse button -->
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
    aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <!-- Collapsible content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links -->
    <ul class="navbar-nav mr-auto">
      <li class="nav-item active">
        <a class="nav-link" href="https://pennylane.ai/qml">Quantum machine learning
          <span class="sr-only">(current)</span>
        </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/install.html">Install</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/plugins.html">Plugins</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.readthedocs.io">Documentation</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://pennylane.ai/blog">Blog</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://qhack.ai"><img src="https://pennylane.ai/img/qhack_plain_black.png"></a>
      </li>
    </ul>
    <!-- Links -->

    <ul class="navbar-nav ml-auto nav-flex-icons">
      <li class="nav-item">
        <a class="nav-link" href="http://pennylane.ai/faq.html">
          <i class="fab fas fa-question"></i> FAQ
        </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://discuss.pennylane.ai">
          <i class="fab fab fa-discourse"></i> Support
        </a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://github.com/XanaduAI/PennyLane">
          <i class="fab fa-github"></i> GitHub
        </a>
      </li>
    </ul>
  </div>
  <!-- Collapsible content -->
</nav>
<!--/.Navbar-->
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial_noisy_circuit_optimization.html" title="Optimizing noisy circuits with Cirq"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial_isingmodel_PyTorch.html" title="3-qubit Ising model in PyTorch"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_basics.html" accesskey="U">Basics</a> &#187;</li> 
      </ul>
    </div>
        <div id="content">


          <div id="right-column">
            <div class="document clearer body">

              <div class="container-wrapper">

                <div role="navigation" aria-label="breadcrumbs navigation">
                  <ol class="breadcrumb">
                  </ol>
                </div>

              
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-demos-pytorch-noise-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="pytorch-and-noisy-devices">
<span id="pytorch-noise"></span><span id="sphx-glr-demos-pytorch-noise-py"></span><h1>PyTorch and noisy devices<a class="headerlink" href="#pytorch-and-noisy-devices" title="Permalink to this headline">¶</a></h1>
<p><script type="text/javascript">
    var related_tutorials = ["tutorial_noisy_circuit_optimization.html"];
    var related_tutorials_titles = ['Optimizing noisy circuits with Cirq'];
</script></p>
<p><em>Author: PennyLane dev team. Last updated: 16 Jun 2021.</em></p>
<p>Let’s revisit the original <a class="reference internal" href="tutorial_qubit_rotation.html#qubit-rotation"><span class="std std-ref">qubit rotation</span></a> tutorial, but instead of
using the default NumPy/autograd QNode interface, we’ll use the <a class="reference external" href="https://pennylane.readthedocs.io/en/stable/introduction/interfaces/torch.html" title="(in PennyLane v0.17)"><span>PyTorch interface</span></a>.
We’ll also replace the <code class="docutils literal notranslate"><span class="pre">default.qubit</span></code> device with a noisy <code class="docutils literal notranslate"><span class="pre">forest.qvm</span></code>
device, to see how the optimization responds to noisy qubits. At the end of the
demonstration, we will also show a way of how Rigetti’s QPU can be used via
Amazon Braket.</p>
<p>To follow along with this tutorial on your own computer, you will require the
following dependencies:</p>
<ul>
<li><p class="first">The <a class="reference external" href="https://rigetti.com/forest">Forest SDK</a>, which contains the quantum virtual
machine (QVM) and quilc quantum compiler. Once installed, the QVM and quilc can be
started by running the commands <code class="docutils literal notranslate"><span class="pre">quilc</span> <span class="pre">-S</span></code> and <code class="docutils literal notranslate"><span class="pre">qvm</span> <span class="pre">-S</span></code> in separate terminal windows.</p>
</li>
<li><p class="first"><a class="reference external" href="https://pennylane-forest.readthedocs.io">PennyLane-Forest plugin</a>, in order
to access the QVM as a PennyLane device. This can be installed via pip:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install pennylane-forest
</pre></div>
</div>
</li>
<li><p class="first"><a class="reference external" href="https://amazon-braket-pennylane-plugin-python.readthedocs.io/en/latest/">PennyLane-Braket plugin</a>, in order
to access the Rigetti QPU as a PennyLane device. This can be installed via
pip:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install amazon-braket-pennylane-plugin
</pre></div>
</div>
</li>
<li><p class="first"><a class="reference external" href="https://pytorch.org/get-started/locally/">PyTorch</a>, in order to access the PyTorch
QNode interface. Follow the link for instructions on the best way to install PyTorch
for your system.</p>
</li>
</ul>
<div class="section" id="setting-up-the-device">
<h2>Setting up the device<a class="headerlink" href="#setting-up-the-device" title="Permalink to this headline">¶</a></h2>
<p>Once the dependencies above are installed, let’s begin importing the required packages
and setting up our quantum device.</p>
<p>To start with, we import PennyLane, and, as we are using the PyTorch interface,
PyTorch as well:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</pre></div>
</div>
<p>Note that we do not need to import the wrapped version of NumPy provided by PennyLane,
as we are not using the default QNode NumPy interface. If NumPy is needed, it is fine to
import vanilla NumPy for use with PyTorch and TensorFlow.</p>
<p>Next, we will create our device:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dev</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;forest.qvm&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;2q&quot;</span><span class="p">,</span> <span class="n">noisy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we create a noisy two-qubit system, simulated via the QVM. If we wish, we could
also build the model on a physical device, such as the <code class="docutils literal notranslate"><span class="pre">Aspen-1</span></code> QPU which
can be accessed through Amazon Braket (more details on that will follow).</p>
</div>
<div class="section" id="constructing-the-qnode">
<h2>Constructing the QNode<a class="headerlink" href="#constructing-the-qnode" title="Permalink to this headline">¶</a></h2>
<p>Now that we have initialized the device, we can construct our quantum node. Like the
other tutorials, we use the <code class="xref py py-mod docutils literal notranslate"><span class="pre">qnode</span></code> decorator to convert
our quantum function (encoded by the circuit above) into a quantum node
running on the QVM.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">circuit</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.RX.html#pennylane.RX" title="pennylane.RX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qml</span><span class="o">.</span><span class="n">RX</span></a><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.RZ.html#pennylane.RZ" title="pennylane.RZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qml</span><span class="o">.</span><span class="n">RZ</span></a><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<p>To make the QNode ‘PyTorch aware’, we need to specify that the QNode interfaces
with PyTorch. This is done by passing the <code class="docutils literal notranslate"><span class="pre">interface='torch'</span></code> keyword argument.</p>
<p>As a result, this QNode will be set up to accept and return PyTorch tensors, and will
also automatically calculate any analytic gradients when PyTorch performs backpropagation.</p>
</div>
<div class="section" id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">¶</a></h2>
<p>We can now create our optimization cost function. To introduce some additional
complexity into the system, rather than simply training the variational circuit
to ‘flip a qubit’ from state <span class="math notranslate nohighlight">\(\left|0\right\rangle\)</span> to state <span class="math notranslate nohighlight">\(\left|1\right\rangle\)</span>, let’s also
modify the target state every 100 steps. For example, for the first 100 steps,
the target state will be <span class="math notranslate nohighlight">\(\left|1\right\rangle\)</span>; this will then change to <span class="math notranslate nohighlight">\(\left|0\right\rangle\)</span>
for steps 100 and 200, before changing back to state <span class="math notranslate nohighlight">\(\left|1\right\rangle\)</span> for steps 200
to 300, and so on.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">target</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="mi">100</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">circuit</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
</pre></div>
</div>
<p>Now that the cost function is defined, we can begin the PyTorch optimization.
We create two variables, representing the two free parameters of the variational
circuit, and initialize an Adam optimizer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">phi</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<p>As we are using the PyTorch interface, we must use PyTorch optimizers,
<em>not</em> the built-in optimizers provided by PennyLane. The built-in optimizers
only apply to the default NumPy/autograd interface.</p>
<p>Optimizing the system for 400 steps:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">400</span><span class="p">):</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>We can now check the final values of the parameters, as well as the final
circuit output and cost function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">circuit</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cost</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="mi">400</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor(-0.7055, requires_grad=True)
tensor(6.1330, requires_grad=True)
tensor(0.9551, dtype=torch.float64, grad_fn=&lt;_TorchQNodeBackward&gt;)
tensor(3.7162, dtype=torch.float64, grad_fn=&lt;PowBackward0&gt;)
</pre></div>
</div>
<p>As the cost function is step-dependent, this does not provide enough detail to
determine if the optimization was successful; instead, let’s plot the output
state of the circuit over time on a Bloch sphere:</p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0);"><img alt="../_images/bloch.gif" src="../_images/bloch.gif" /></a>
</div>
<p>Here, the red x is the target state of the variational circuit, and the arrow is
the variational circuit output state. As the target state changes, the circuit
learns to produce the new target state!</p>
</div>
<div class="section" id="hybrid-gpu-qpu-optimization">
<h2>Hybrid GPU-QPU optimization<a class="headerlink" href="#hybrid-gpu-qpu-optimization" title="Permalink to this headline">¶</a></h2>
<p>As PyTorch natively supports GPU-accelerated classical processing, and Amazon
Braket provides quantum hardware access in the form of QPUs, we can run the above code
as a hybrid GPU-QPU optimization with very little modification.</p>
<p>Note that to run the following script, you will need access to Rigetti’s QPU.
To connect to a QPU, we can use Amazon Braket. For a dedicated demonstration
on using Amazon Braket, see our tutorial on
<a class="reference external" href="https://pennylane.ai/qml/demos/braket-parallel-gradients.html">Computing gradients in parallel with Amazon Braket</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="n">my_bucket</span> <span class="o">=</span> <span class="s2">&quot;amazon-braket-Your-Bucket-Name&quot;</span>  <span class="c1"># the name of the bucket</span>
<span class="n">my_prefix</span> <span class="o">=</span> <span class="s2">&quot;Your-Folder-Name&quot;</span>  <span class="c1"># the name of the folder in the bucket</span>
<span class="n">s3_folder</span> <span class="o">=</span> <span class="p">(</span><span class="n">my_bucket</span><span class="p">,</span> <span class="n">my_prefix</span><span class="p">)</span>

<span class="n">device_arn</span> <span class="o">=</span> <span class="s2">&quot;arn:aws:braket:::device/qpu/rigetti/Aspen-9&quot;</span>

<span class="n">qpu</span> <span class="o">=</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span>
    <span class="s2">&quot;braket.aws.qubit&quot;</span><span class="p">,</span>
    <span class="n">device_arn</span><span class="o">=</span><span class="n">device_arn</span><span class="p">,</span>
    <span class="n">wires</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">s3_destination_folder</span><span class="o">=</span><span class="n">s3_folder</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Note: swap dev to qpu here to use the QPU</span>
<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">circuit</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.RX.html#pennylane.RX" title="pennylane.RX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qml</span><span class="o">.</span><span class="n">RX</span></a><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.RZ.html#pennylane.RZ" title="pennylane.RZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qml</span><span class="o">.</span><span class="n">RZ</span></a><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><a href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="mi">0</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">target</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="mi">100</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">circuit</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>


<span class="n">phi</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">400</span><span class="p">):</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>When using a classical interface that supports GPUs, the QNode will automatically
copy any tensor arguments to the CPU, before applying them on the specified quantum
device. Once done, it will return a tensor containing the QNode result, and
automatically copy it back to the GPU for any further classical processing.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For more details on the PyTorch interface, see <a class="reference external" href="https://pennylane.readthedocs.io/en/stable/introduction/interfaces/torch.html" title="(in PennyLane v0.17)"><span>PyTorch interface</span></a>.</p>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-pytorch-noise-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<a class="reference download internal" download="" href="../_downloads/d34cd303e8ff476148eea0a13f721de2/pytorch_noise.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">pytorch_noise.py</span></code></a></div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<a class="reference download internal" download="" href="../_downloads/f6c9deb0b8e2d98b166c1ead407aa274/pytorch_noise.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">pytorch_noise.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/pytorch_noise</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>
            </div>
          </div>
              <div class="comment-container nano has-scrollbar">
  <div class="nano-content">
    
    <div id="comments">
      <h3>Contents</h3>
      <ul>
<li><a class="reference internal" href="#">PyTorch and noisy devices</a><ul>
<li><a class="reference internal" href="#setting-up-the-device">Setting up the device</a></li>
<li><a class="reference internal" href="#constructing-the-qnode">Constructing the QNode</a></li>
<li><a class="reference internal" href="#optimization">Optimization</a></li>
<li><a class="reference internal" href="#hybrid-gpu-qpu-optimization">Hybrid GPU-QPU optimization</a></li>
</ul>
</li>
</ul>

    </div>
    
    <div class="xanadu-call-to-action-links">
      <h3>Downloads</h3>
      <div id="tutorial-type">demos/pytorch_noise</div>
      <div class="download-python-link">
        <i class="fab fa-python"></i>&nbsp;
        <div class="call-to-action-desktop-view">Download Python script</div>
      </div>
      <div class="download-notebook-link">
        <i class="fas fa-download"></i>&nbsp;
        <div class="call-to-action-desktop-view">Download Notebook</div>
      </div>
      <div class="github-view-link">
        <i class="fab fa-github"></i>&nbsp;
        <div class="call-to-action-desktop-view">View on GitHub</div>
      </div>
      <div id="related-tutorials" class="mt-4">
      <h3> Related tutorials</h3>
      </div>
    </div>
  </div>
</div>
            

          <div class="up-button">
            
              
                <a href="../demos_basics.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>


    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial_noisy_circuit_optimization.html" title="Optimizing noisy circuits with Cirq"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial_isingmodel_PyTorch.html" title="3-qubit Ising model in PyTorch"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_basics.html" >Basics</a> &#187;</li> 
      </ul>
    </div>

    <!-- JQuery -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <!-- Bootstrap core JavaScript -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
    <!-- MDB core JavaScript -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
    <!-- Nanoscroller -->
    <script type="text/javascript" src="../_static/js/nanoscroller.min.js"></script>
    <script type="text/javascript">
        $('a.reference.external').each(function(){
          var link = $(this).attr("href");
          var hash = link.split('#')[1];
          var page = link.split('#')[0].split('/').slice(-1)[0].replace(".html", "");
          if (hash == page) {
            $(this).attr('href', link.split('#')[0]);
          }
        });
        $(".document > .section").removeClass("section");
        var tocContainer = document.querySelector('.comment-container');
        tocContainer.style.height = '85vh';
        $(".nano").nanoScroller();
    </script>
    <!-- lightslider -->
    <script src="../_static/js/lightslider.min.js"></script>

    <script type="text/javascript">
      $(window).scroll(function(){
          var windowHeight = window.innerHeight;
          var footer = document.querySelector('.page-footer');
          var footerPosition = footer.getBoundingClientRect();
          var tocContainer = document.querySelector('.comment-container');

          // Check if the footer is visible
          if (footerPosition.top < windowHeight && footerPosition.bottom >= 0) {
              // We want the height of the TOC to be the height of the main content minus how much of the footer is visible.
              tocContainer.style.height = 'calc(85vh - 45px - ' + (windowHeight - footerPosition.top) + 'px)'
          } else {
            // When the user scrolls back to the top of the page after scrolling to the bottom of the page,
            // We want to reset the TOC container back to it's original height
            if (tocContainer.style.height !== '85vh') tocContainer.style.height = '85vh';
          }
      });
      $(document).ready(function () {
          $(".css-transitions-only-after-page-load").each(function (index, element) {
              setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
          });
      });
    </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "XanaduAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href,
          notebookDownloadPath = notebookLink.split('_downloads')[1].split('/').pop();

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();
      }
    </script>


    <script type="text/javascript">
        $(document).ready(function() {
            $("#featured-demos").lightSlider({
                item: 3,
                autoWidth: false,
                slideMove: 1, // slidemove will be 1 if loop is true
                slideMargin: 0,
                auto: true,
                loop: true,
                controls: true,
                pause: 5000,
                pager: false,
                prevHtml: "<i class='fas fa-chevron-left black-text' style='font-size: xx-large;'></i>",
                nextHtml: "<i class='fas fa-chevron-right black-text' style='font-size: xx-large;'></i>",
                responsive : [
                    {
                        breakpoint:1400,
                        settings: {
                            item:2,
                            slideMove:1,
                            slideMargin:0,
                          }
                    },
                    {
                        breakpoint:768,
                        settings: {
                            item:1,
                            slideMove:1,
                            slideMargin:6,
                          }
                    }
                ]
            });
        });
    </script>


  <footer class="page-footer text-md-left pt-4">
  
    <hr class="pb-0 mb-0">
    <div class="container-fluid">
      <div class="row   justify-content-md-center">
        <div class="col-md-3">
          <h5 class=" mb-1 footer-heading">Xanadu</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <p class="">Located in the heart of downtown Toronto, we've brought together exceptional minds from around the world to build quantum computers that are useful and available to people everywhere.</p>
        </div>

    <div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">PennyLane</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://pennylane.ai/">Home page</a></li>
            <li><a class="" href="https://github.com/XanaduAI/pennylane">GitHub</a></li>
            <li><a class="" href="https://pennylane.readthedocs.io/">Documentation</a></li>
            <li><a class="" href="https://discuss.pennylane.ai/">Discussion forum</a></li>
            <li><a class="" href="https://twitter.com/pennylaneai/">Twitter</a></li>
          </ul>
        </div>
		<div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">Strawberry Fields</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://strawberryfields.ai/">Interactive</a></li>
            <li><a class="" href="https://github.com/XanaduAI/strawberryfields">GitHub</a></li>
            <li><a class="" href="https://strawberryfields.readthedocs.io/">Documentation</a></li>
            <li><a class="" href="https://u.strawberryfields.ai/slack/">Slack channel</a></li>
          </ul>
        </div>


        <div class="col-md-2 col-4">
          <h5 class=" mb-1 footer-heading">About</h5>
          <hr width=100px class="d-inline-block mt-0 mb-1 Deep-purple accent-4">
          <ul class="list-unstyled">
            <li><a class="" href="https://www.xanadu.ai/">Home</a></li>
            <li><a class="" href="https://www.xanadu.ai/hardware/">Hardware</a></li>
            <li><a class="" href="https://www.xanadu.ai/software/">Software</a></li>
            <li><a class="" href="https://www.xanadu.ai/research">Research</a></li>
            <li><a class="" href="https://medium.com/XanaduAI">Blog</a></li>
            <li><a class="" href="https://www.xanadu.ai/about/">About</a></li>
          </ul>
        </div>
      </div>
    </div>
    <hr>

    <!-- <hr class="pb-0 mb-0"> -->

    <!--Social buttons-->
    <div class="social-section text-center">
        <ul class="list-unstyled list-inline mb-0">
            <li class="list-inline-item"><a class="btn-fb" href="https://www.facebook.com/Xanadu-1312050742230493/"><i class="fab fa-facebook-f"> </i></a></li>
            <li class="list-inline-item"><a class="btn-tw" href="https://twitter.com/xanaduai"><i class="fab fa-twitter"> </i></a></li>
            <li class="list-inline-item"><a class="" href="https://medium.com/xanaduai"><i class="fab fa-medium-m"> </i></a></li>
            <li class="list-inline-item"><a class="btn-li" href="https://www.linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
            <li class="list-inline-item"><a class="btn-git" href="https://github.com/XanaduAI"><i class="fab fa-github"> </i></a></li>
        </ul>
        <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">Stay updated with our newsletter</a>
    </div>
    <!--/.Social buttons-->

    <!--Copyright-->
    <div class="footer-copyright py-3 mt-0 text-center">
        <div class="container-fluid">
            © Copyright 2019 | Xanadu | All rights reserved
            <br>
             TensorFlow, the TensorFlow logo and any related marks are trademarks of Google Inc. 
        </div>
    </div>
  </footer>
  </body>
</html>